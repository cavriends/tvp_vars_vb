{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 39\n"
     ]
    }
   ],
   "source": [
    "train = 200\n",
    "\n",
    "M = 3\n",
    "p = 4\n",
    "T = train - p\n",
    "k = M*(M*p+1)\n",
    "\n",
    "print(\"k: \" + str(k))\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(series, code, transform=True):\n",
    "    \n",
    "    if transform:\n",
    "        if code == 1:\n",
    "            # none\n",
    "            transformed_series = series\n",
    "        elif code == 2:\n",
    "            # first-difference\n",
    "            transformed_series = first_difference = series[1:] - series[:-1]\n",
    "        elif code == 3:\n",
    "            # second-difference\n",
    "            transformed_series = series[2:] - series[:-2]\n",
    "        elif code == 4:\n",
    "            # log\n",
    "            transformed_series = np.log(series)\n",
    "        elif code == 5:\n",
    "            # first-difference log\n",
    "            transformed_series = np.log(series[1:]) - np.log(series[:-1])\n",
    "        elif code == 6:\n",
    "            # second-difference log\n",
    "            transformed_series = np.log(series[2:]) - np.log(series[:-2])\n",
    "\n",
    "        return transformed_series\n",
    "    else:\n",
    "        return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"data/fred_qd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=True\n",
    "\n",
    "gdp = transformation(ds[\"GDPC1\"].iloc[2:].to_numpy(), 5, transform)\n",
    "cpi = transformation(ds[\"CPIAUCSL\"].iloc[2:].to_numpy(), 6, transform)\n",
    "fedfund = transformation(ds[\"FEDFUNDS\"].iloc[2:].to_numpy(), 2, transform)\n",
    "compi = transformation(ds[\"PPIACO\"].iloc[2:].to_numpy(), 6, transform)\n",
    "borrowings = transformation(ds[\"TOTRESNS\"].iloc[2:].to_numpy(), 6, transform)\n",
    "sp500 = transformation(ds[\"S&P 500\"].iloc[2:].to_numpy(), 5, transform)\n",
    "m2 = transformation(ds[\"M2REAL\"].iloc[2:].to_numpy(), 5, transform)\n",
    "\n",
    "series_total = [gdp, cpi, fedfund]\n",
    "#series_total = [gdp, cpi, fedfund, compi, borrowings , sp500, m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(series, train_indices, T, M, p):\n",
    "    \n",
    "    # Create data\n",
    "    lagged_y = np.ones((T,M*p+1))\n",
    "    lagged_series = []\n",
    "    y_series = []\n",
    "    \n",
    "    for s in series:\n",
    "        lagged_series.append(s[:train_indices])\n",
    "\n",
    "    position_counter = 1 #Constant is added in front\n",
    "\n",
    "    for m in range(M):\n",
    "        y_m = lagged_series[m]\n",
    "        for i in range(1,p+1):\n",
    "            lagged_y[:,position_counter] = y_m[(p-i):-i]\n",
    "            position_counter += 1\n",
    "\n",
    "    # Create lagged dependent matrix   \n",
    "    X = np.zeros((T,M,k))\n",
    "    stacked_X = np.zeros((M,T,k))\n",
    "\n",
    "    for m in range(M):\n",
    "        total_lags = M*p+1\n",
    "        stacked_X[m,:,m*(total_lags):(m+1)*total_lags] = lagged_y\n",
    "\n",
    "    stacked_list = list()\n",
    "\n",
    "    for m in range(M):\n",
    "        stacked_list.append(stacked_X[m])\n",
    "\n",
    "    for t in range(T):\n",
    "        X[t] = np.squeeze(np.dstack(tuple(stacked_list)))[t].T\n",
    "    \n",
    "    for s in series:\n",
    "        y_series.append(s[p:train_indices])\n",
    "        \n",
    "    y = np.array(y_series)\n",
    "    y = y.T\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrices from FED-QD\n",
    "X, y = create_data(series_total, train, T, M, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dgp_data():\n",
    "\n",
    "    # Create data\n",
    "    lagged_y = np.zeros((T,M*p))\n",
    "\n",
    "    locations = np.random.randint(0,10,size=M)\n",
    "    position_counter = 0\n",
    "\n",
    "    for m in range(M):\n",
    "        y_m = np.random.normal(loc=locations[m], scale=2, size=T+p)\n",
    "        for i in range(1,p+1):\n",
    "            lagged_y[:,position_counter] = y_m[(p-i):-i]\n",
    "            position_counter += 1\n",
    "\n",
    "    # Create lagged dependent matrix   \n",
    "    X = np.zeros((T,M,k))\n",
    "    stacked_X = np.zeros((M,T,k))\n",
    "\n",
    "    for m in range(M):\n",
    "        total_lags = M*p\n",
    "        stacked_X[m,:,m*(total_lags):(m+1)*total_lags] = lagged_y\n",
    "\n",
    "    stacked_list = list()\n",
    "\n",
    "    for m in range(M):\n",
    "        stacked_list.append(stacked_X[m])\n",
    "\n",
    "    for t in range(T):\n",
    "        X[t] = np.squeeze(np.dstack(tuple(stacked_list)))[t].T\n",
    "\n",
    "    # Create betas\n",
    "    ub = 5\n",
    "    lb = 0\n",
    "    difference = 0.5\n",
    "    scale = 0.010\n",
    "    sign = -1\n",
    "\n",
    "    beta = np.zeros((T,k))\n",
    "\n",
    "    for i in range(k):\n",
    "        bound = np.random.randint(lb,ub)\n",
    "\n",
    "        if sign == 1:\n",
    "            sign = -1\n",
    "        else:\n",
    "            sign = 1\n",
    "\n",
    "        beta[:,i] = np.linspace(bound,bound+sign*difference,T) + np.random.normal(scale=scale,size=T)\n",
    "\n",
    "        #beta[:,27:32] = 0\n",
    "        beta[50:125,2] = 0\n",
    "\n",
    "    # Construct dependent\n",
    "    y = np.zeros((M,T))\n",
    "\n",
    "    for i in range(T):\n",
    "        y[:,i] = X[i]@beta[i] + np.random.normal(size=M).T #np.random.multivariate_normal(mean=np.zeros(2), cov=np.diag([0.10,5]))\n",
    "\n",
    "    # Transpose for KF\n",
    "    y = y.T\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvp_var_vb(X, y, T, m, p, k, prior='svss', prior_parameters = {'tau_0':0.1, 'tau_1':10, 'pi0':0.5}, prior_default=True, homoskedastic=True, iterations=1000, threshold=1.0e-4, print_status=True):\n",
    "    \n",
    "    #Priors\n",
    "    # 1) beta_0 ~ N(m0,S0)\n",
    "    m0 = np.zeros(k) \n",
    "    S0 = 4*np.eye(k)\n",
    "    \n",
    "    # 2) q_t ~ Gamma(ct,dt)\n",
    "    ct = np.ones((T,k)) \n",
    "    dt = np.ones((T,k))  \n",
    "    d0 = 1\n",
    "    c0 = 25\n",
    "\n",
    "    if prior == 'svss':\n",
    "        # 3) SVSS\n",
    "        # Default {'tau_0':0.1, 'tau_1':10, 'pi0':0.5}\n",
    "        if prior_default:\n",
    "            prior_parameters = {'tau_0':0.1, 'tau_1':10, 'pi0':0.5}\n",
    "            \n",
    "        tau_0 = prior_parameters['tau_0']\n",
    "        tau_1 = prior_parameters['tau_1']\n",
    "        pi0 = prior_parameters['pi0']\n",
    "        tv_probs = np.ones((T,k))\n",
    "    elif prior == 'horseshoe':\n",
    "        # 4) Horseshoe \n",
    "        # Default: {'a0':10,'b0':10}\n",
    "        if prior_default:\n",
    "            prior_parameters = {'a0':10,'b0':10}\n",
    "            \n",
    "        a0_horseshoe = prior_parameters['a0']\n",
    "        b0_horseshoe = prior_parameters['b0']\n",
    "        lambda_t_horseshoe = np.ones(T)\n",
    "        phi_t = np.ones((T,k))\n",
    "    elif prior == 'lasso':\n",
    "        # 5) Lasso\n",
    "        # Default {'lambda_param':50}\n",
    "        if prior_default:\n",
    "            prior_parameters = {'lambda_param':50}\n",
    "        tau_lasso = np.ones((T,k))\n",
    "        lambda_param = prior_parameters['lambda_param']\n",
    "        \n",
    "    if homoskedastic:\n",
    "        # 6) sigma ~ Gamma(at, bt) - homoskedastic\n",
    "        at_h = np.ones(M)\n",
    "        a0_h = 1\n",
    "        bt_h = np.ones(M)\n",
    "        b0_h = 1\n",
    "    else:\n",
    "        # 7) sigma_t ~ Gamma(at,bt) - heteroskedastic\n",
    "        at = np.ones((T,M))\n",
    "        a0 = 1e-2\n",
    "        bt = np.ones((T,M))\n",
    "        b0 = 1e-2\n",
    "    \n",
    "    sigma_t = 0.1*np.ones((T,M))\n",
    "\n",
    "    mtt  = np.zeros((k,T))\n",
    "    mt1t = np.zeros((k,T))\n",
    "    mtt1 = np.zeros((k,T))\n",
    "    Stt  = np.zeros((k,k,T))\n",
    "    Stt1 = np.zeros((k,k,T))\n",
    "\n",
    "    lambda_t = np.zeros((T,k))\n",
    "    q_t      = np.ones((T,k))\n",
    "    Qtilde   = np.zeros((k,k,T))\n",
    "    Ftilde   = np.zeros((k,k,T))\n",
    "    \n",
    "    offset    = 0.0015\n",
    "    delta     = 0.9\n",
    "\n",
    "    elapsed_time = 0\n",
    "    start_time = 0\n",
    "    counter = 0\n",
    "    mt1t_previous = np.ones((k,T))\n",
    "    difference_parameters = np.zeros(iterations)\n",
    "\n",
    "    while (counter < iterations) & (np.linalg.norm(mt1t - mt1t_previous) > threshold):\n",
    "\n",
    "        difference_parameters[counter] = np.linalg.norm(mt1t - mt1t_previous)\n",
    "        mt1t_previous = mt1t\n",
    "        start_iteration = time.time()\n",
    "    \n",
    "        if print_status:\n",
    "            if (counter % 10) == 0:\n",
    "                if counter != 0:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "\n",
    "                start_time = time.time()\n",
    "                clear_output(wait=True)\n",
    "                print(\"Iteration: \" + str(counter) + \"\\n\" + \"Elapsed time: \" + str(elapsed_time) + \" seconds\")\n",
    "\n",
    "            if (counter == iterations):\n",
    "                clear_output(wait=True)\n",
    "                print(\"Done!\")\n",
    "\n",
    "        # Kalman filter\n",
    "        # ==================| Update \\beta_{t} using Kalman filter/smoother\n",
    "        for t in range(T):\n",
    "            if prior == 'none':\n",
    "                Qtilde[:,:,t]  = np.diag(1/(q_t[t,:]))\n",
    "                Ftilde[:,:,t]  = np.eye(k)\n",
    "            elif prior == 'svss':\n",
    "                Qtilde[:,:,t]  = np.diag(1/(q_t[t,:] + lambda_t[t,:]))           \n",
    "                Ftilde[:,:,t]  = np.multiply(Qtilde[:,:,t],np.diag(q_t[t,:]))\n",
    "            elif prior == 'horseshoe':\n",
    "                Qtilde[:,:,t]  = np.diag(1/(q_t[t,:] + lambda_t_horseshoe[t]*phi_t[t,:]))           \n",
    "                Ftilde[:,:,t]  = np.multiply(Qtilde[:,:,t],np.diag(q_t[t,:]))\n",
    "            elif prior == 'lasso':\n",
    "                Qtilde[:,:,t]  = np.diag(1/(q_t[t,:] + tau_lasso[t,:]))           \n",
    "                Ftilde[:,:,t]  = np.multiply(Qtilde[:,:,t],np.diag(q_t[t,:]))\n",
    "                \n",
    "            if t==0:\n",
    "                mtt1[:,t]   = Ftilde[:,:,t]@m0;               \n",
    "                Stt1[:,:,t] = Ftilde[:,:,t]@S0@Ftilde[:,:,t].T\n",
    "            else:\n",
    "                mtt1[:,t]   = Ftilde[:,:,t]@mtt[:,t-1]\n",
    "                Stt1[:,:,t] = Ftilde[:,:,t]@Stt[:,:,t-1]@Ftilde[:,:,t].T + Qtilde[:,:,t]\n",
    "\n",
    "            Sx              = Stt1[:,:,t]@X[t,:].T        \n",
    "            Kt              = Sx@np.linalg.inv((X[t,:]@Sx + sigma_t[t,:]))\n",
    "            mtt[:,t]        = mtt1[:,t] + Kt@(y[t,:] - X[t,:]@mtt1[:,t])\n",
    "            Stt[:,:,t]      = (np.eye(k) - Kt@X[t,:])@Stt1[:,:,t]\n",
    "        \n",
    "        # Fixed interval smoother    \n",
    "        mt1t = np.zeros((k,T)) \n",
    "        St1t = np.zeros((k,k,T))\n",
    "        mt1t[:,t] = mtt[:,t]\n",
    "        St1t[:,:,t] = Stt[:,:,t]\n",
    "\n",
    "        for t in reversed(range(T-1)):\n",
    "            C = (Stt[:,:,t]@Ftilde[:,:,t+1])@np.linalg.inv(Stt1[:,:,t+1])        \n",
    "            mt1t[:,t]   = mtt[:,t] + C@(mt1t[:,t+1] - mtt1[:,t+1]) \n",
    "            St1t[:,:,t] = Stt[:,:,t] + C@(St1t[:,:,t+1] - Stt1[:,:,t+1])@C.T\n",
    "            \n",
    "        if np.isnan(mt1t).all():\n",
    "            print(\"Fucked up\")\n",
    "\n",
    "        for t in range(T):\n",
    "            eyeF = (np.eye(k) - 2*Ftilde[:,:,t]).T\n",
    "            if t == 0:\n",
    "                D = St1t[:,:,t] + mt1t[:,t]@mt1t[:,t].T + (S0 + m0*m0.T)@eyeF\n",
    "            else:\n",
    "                D = St1t[:,:,t] + mt1t[:,t]@mt1t[:,t].T + (St1t[:,:,t-1] + mt1t[:,t-1]@mt1t[:,t-1].T)@eyeF\n",
    "\n",
    "            # State variances Q_{t}\n",
    "            ct[t,:]     = c0 + 0.5\n",
    "            dt[t,:]     = d0 + np.maximum(1e-10,np.diag(D)/2)\n",
    "            q_t[t,:]    = ct[t,:]/dt[t,:]\n",
    "            \n",
    "        for t in range(T):\n",
    "            if prior == 'svss':\n",
    "                l_0           = norm.logpdf(mt1t[:,t],np.zeros(k),tau_0*np.ones(k))\n",
    "                l_1           = norm.logpdf(mt1t[:,t],np.zeros(k),tau_1*np.ones(k))\n",
    "                gamma         = 1/(np.multiply(1+(np.divide((1-pi0),pi0)),np.exp(l_0-l_1)))\n",
    "                pi0           = np.mean(gamma)\n",
    "                tv_probs[t,:] = gamma\n",
    "                lambda_t[t,:] = (1/(tau_0**2))*np.ones(k)\n",
    "                lambda_t[t,gamma==1] = (1/(tau_1**2))\n",
    "                \n",
    "            elif prior == 'horseshoe':\n",
    "                lambda_t_horseshoe[t] = (a0_horseshoe+1/2*((1/phi_t[t,:])@mt1t[:,t]**2))/k\n",
    "                phi_t[t,:] = b0_horseshoe+(1/lambda_t_horseshoe[t])*mt1t[:,t]**2\n",
    "                \n",
    "            elif prior == 'lasso':\n",
    "                tau_lasso[t,:] = 1/np.sqrt((lambda_param**2/mt1t[:,t]**2))\n",
    "\n",
    "        # Update volatilities\n",
    "        \n",
    "        if homoskedastic:\n",
    "            for m in range(M):\n",
    "\n",
    "                at_h[m] = a0_h + T\n",
    "\n",
    "                for t in range(T):\n",
    "                    updated_b = np.sum(np.power(y[t,m]-X[t,m].T@mt1t[:,t],2))\n",
    "\n",
    "                bt_h[m] = b0_h + updated_b/2\n",
    "\n",
    "                sigma_t[:,m] = bt_h[m]/at_h[m]\n",
    "        \n",
    "        if homoskedastic == False:\n",
    "            s_tinv = np.zeros((T,M));\n",
    "            for t in range(T):           \n",
    "                temp = X[t,:]@(mt1t[:,t]@mt1t[:,t].T + St1t[:,:,t])@X[t,:].T - 2*X[t,:]@mt1t[:,t]@y[t,:] + (1 + offset)*y[t,:]@y[t,:].T;        \n",
    "                if t == 0:\n",
    "                    at[t,:] = a0 + 0.5;\n",
    "                    bt[t,:] = b0 + temp[0]/2;\n",
    "                else:\n",
    "                    at[t,:] = delta*at[t-1,:] + 0.5;\n",
    "                    bt[t,:] = delta*bt[t-1,:] + temp[0]/2;\n",
    "\n",
    "                s_tinv[t,:] = np.divide(at[t,:],bt[t,:]);\n",
    "\n",
    "            # Smooth volatilities\n",
    "            phi = np.zeros((T,M)); \n",
    "            phi[T-1,:] = np.divide(at[T-1,:],bt[T-1,:]);\n",
    "            for t in reversed(range(T-1)):\n",
    "                phi[t,:] = [1-delta]*s_tinv[t,:] + delta*phi[t+1,:];\n",
    "            sigma_t = 1/phi;\n",
    "        \n",
    "        if print_status:\n",
    "            end_iteration = time.time()\n",
    "            iteration_delta = end_iteration - start_iteration\n",
    "            print(\"Seconds for one iteration: \" + str(iteration_delta) + \"\\n\" + \"Difference: \" + str(difference_parameters[counter]))\n",
    "        # Increase counter\n",
    "        counter += 1\n",
    "        \n",
    "    return mt1t, St1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Elapsed time: 0 seconds\n",
      "Seconds for one iteration: 0.15681219100952148\n",
      "Difference: 87.42997197757758\n",
      "Seconds for one iteration: 0.15566205978393555\n",
      "Difference: 6.562720236567238\n",
      "Seconds for one iteration: 0.19759631156921387\n",
      "Difference: 5.8555108578476895\n",
      "Seconds for one iteration: 0.16602277755737305\n",
      "Difference: 0.7993102895976073\n",
      "Seconds for one iteration: 0.14798617362976074\n",
      "Difference: 0.10356991606268767\n",
      "Seconds for one iteration: 0.15212225914001465\n",
      "Difference: 0.021928940103011517\n",
      "Seconds for one iteration: 0.14958715438842773\n",
      "Difference: 0.0062290410511621815\n",
      "Seconds for one iteration: 0.14956903457641602\n",
      "Difference: 0.0016125704434015945\n",
      "Seconds for one iteration: 0.15160799026489258\n",
      "Difference: 0.0005085050389233675\n",
      "Seconds for one iteration: 0.15787482261657715\n",
      "Difference: 0.00015696901022526163\n"
     ]
    }
   ],
   "source": [
    "mt1t, St1t = tvp_var_vb(X, y, T, M, p, k, prior='horseshoe', homoskedastic=True, print_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_T = cpi.shape[0]\n",
    "X_complete, y_complete = create_data(series_total, complete_T, complete_T-4, M, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.empty((T,M))\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    for t in range(T):\n",
    "\n",
    "        y_pred[t,m] = X[t,m,:]@mt1t[:,t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004859186965044514"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_pred - y_complete[:196])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictions(total_h, current_X, mt1t):\n",
    "\n",
    "    prev_X = current_X\n",
    "\n",
    "    prev_pred = np.zeros((M,total_h))\n",
    "\n",
    "    for h in range(total_h):\n",
    "\n",
    "        prev_pred[:,h] = prev_X@mt1t[:,-1]\n",
    "        vec_X = prev_X[0,:(M*p+1)]\n",
    "\n",
    "        empty_X = np.zeros((M*p+1))\n",
    "        empty_X[0] = 1\n",
    "\n",
    "        for m in range(M):\n",
    "            empty_X[(m*p+2):((m+1)*p+1)] = vec_X[(m*p+1):((m+1)*p)]\n",
    "\n",
    "        vec_X = empty_X\n",
    "        vec_X[1::p] = prev_pred[:,h]\n",
    "\n",
    "        prev_X = np.zeros((M,k))\n",
    "        for m in range(M):\n",
    "            total_lags = M*p+1\n",
    "            prev_X[m,m*(total_lags):(m+1)*total_lags] = vec_X\n",
    "\n",
    "    return prev_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_msfe(X_complete, y_complete, p, train_begin=200, complete_T=243, total_h=8, prior='svss', prior_parameters={'tau_0':0.1, 'tau_1':10, 'pi0':0.5} ,homoskedastic=True):\n",
    "\n",
    "    y_pred = np.zeros((complete_T-train_begin,M,total_h))\n",
    "    counter = 0\n",
    "    MSFE_TVP = np.zeros(total_h)\n",
    "    for idx, t in enumerate(range(train_begin, complete_T)):\n",
    "\n",
    "        train_T = t-p\n",
    "        X_train = X_complete[:train_T]\n",
    "        y_train = y_complete[:train_T]\n",
    "        counter += 1\n",
    "        mt1t, St1t = tvp_var_vb(X_train, y_train, train_T, M, p, k, prior=prior, homoskedastic=homoskedastic, prior_parameters=prior_parameters, prior_default=False, print_status=False)\n",
    "\n",
    "        y_pred[idx] = calculate_predictions(total_h, X_complete[train_T], mt1t)\n",
    "    \n",
    "    for h in range(total_h):\n",
    "        if h == 0:\n",
    "            MSFE_TVP[h] = np.mean((y_complete[train_begin-p:]-y_pred[:,:,0])**2)\n",
    "        else:\n",
    "            MSFE_TVP[h] = np.mean((y_complete[train_begin-p+h:]-y_pred[:-h,:,h])**2)\n",
    "            \n",
    "    return MSFE_TVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h in range(total_h):\n",
    "#     if h == 0:\n",
    "#         MSFE_TVP = np.mean((y_complete[train_begin-p:]-y_pred[:,:,0])**2)\n",
    "#         MSFE_RW = np.mean((y_complete[train_begin-p:]-y_complete[train_begin-p-1:-1])**2)\n",
    "#     else:\n",
    "#         MSFE_TVP = np.mean((y_complete[train_begin-p+h:]-y_pred[:-h,:,h])**2)\n",
    "#         MSFE_RW = np.mean((y_complete[train_begin-p:]-y_complete[train_begin-p-(h+1):-(h+1)])**2)\n",
    "              \n",
    "#     print(str(h+1) + \"-step ahead\" + \"\\n\" + \"MSFE TVP-VAR: \" + \"\\t\" + str(round(MSFE_TVP,4)) + \"\\n\" + \"MSFE RW: \" + \"\\t\" + str(round(MSFE_RW,4)) + \"\\n\" + \"Ratio: \" + str(round(MSFE_TVP/MSFE_RW,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# lambda_values = np.arange(50,51,0.20)\n",
    "# derivative_values = np.zeros(lambda_values.shape[0])\n",
    "# error = np.sqrt(1.1e-16)\n",
    "\n",
    "# for idx, lambda_value in enumerate(lambda_values):\n",
    "                                   \n",
    "#     derivative_values[idx] = (calculate_msfe(X_complete, y_complete, p, prior='lasso', prior_parameters={'lambda_param':lambda_value+error})[0] - calculate_msfe(X_complete, y_complete, p, prior='lasso', prior_parameters={'lambda_param':lambda_value-error})[0])/(2*error)\n",
    "#     print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative (parameter_value):\n",
    "    error = np.sqrt(1.1e-16)\n",
    "    derivative = (calculate_msfe(X_complete, y_complete, p, prior='lasso', prior_parameters={'lambda_param':parameter_value+error})[0] - calculate_msfe(X_complete, y_complete, p, prior='lasso', prior_parameters={'lambda_param':parameter_value-error})[0])/(2*error)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "lambda_values = np.arange(50,51,0.5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.map(calculate_derivative, lambda_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
