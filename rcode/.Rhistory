# Input:
#
# x     data set with missing values
# R     number of bootstrap replications
# k     number of neighbors for kNN imputation
# DDC   a logical indicating whether to run the DetectDeviatingCells algorithm
#       before performing imputation (such that the flagged outlying cells are
#       also imputed)
# ...   additional arguments to be passed to modeling function (for example,
#       control parameters for the MM-algorithm)
#
# Output:
# A list with the following components:
# replicates   a matrix with all coefficient estimates from all replications
# summary      a matrix that contains the point estimates of the coefficients
#              in the first column, the standard errors in the second column,
#              the z-statistic in the third column, and the p-value in the
#              fourth column (see slide 29 of Lecture 5 for an example)
bootstrap <- function(x, R = 200, k = 10, DDC = FALSE, ...) {
p = ncol(x)
n = nrow(x)
bootstrapped_estimates = list()
for (i in seq(R)) {
x_r = x[sample(seq(n), n, replace = TRUE),]
if (DDC == TRUE) {
x_r_imputed = cellWise::DDC(x_r, DDCpars = list("silent" = TRUE))$remX
} else {
x_r_imputed = kNN(data.frame(x_r), k = k)[,1:p]
}
# Set last column to y
colnames(x_r_imputed) = colnames(x_r_imputed, do.NULL = FALSE)
colnames(x_r_imputed)[ncol(x_r_imputed)] = "y"
bootstrapped_estimates = append(bootstrapped_estimates, list(lmrob(y ~ ., data = data.frame(x_r_imputed))$coefficients))
if (i == R) {
coefficient_matrix = matrix(unlist(bootstrapped_estimates), ncol = p, byrow = TRUE)
point_estimates = apply(coefficient_matrix, 2, mean)
standard_errors = sqrt(diag(cov(coefficient_matrix)))
}
}
z_statistic = point_estimates/standard_errors
p_values = 1 - pnorm(z_statistic)
summary_matrix = matrix(0, nrow = p, ncol = 4)
summary_matrix[,1] = point_estimates
summary_matrix[,2] = standard_errors
summary_matrix[,3] = z_statistic
summary_matrix[,4] = p_values
return_list = list("replicates" = coefficient_matrix,
"summary" = summary_matrix)
return(return_list)
}
print(summary(clean_result))
print(pool(fit(multimp(xy, m = 20))))
bootstrap(xy)$summary
View(xy)
data("airquality")
force(airquality)
View(airquality)
View(airquality)
library(VIM)
library(cellWise)
library(robustbase)
data("airquality")
multimp <- function(xy, m = 10, DDC = FALSE, ...) {
p = ncol(xy)
n = nrow(xy)
if (DDC == TRUE) {
indices = cellWise::DDC(xy[,1:(p-1)], DDCpars = list("silent" = TRUE))$indall
vectorized_xy = c(xy[,1:(p-1)])
vectorized_xy[indices] = NA
xy = cbind(matrix(vectorized_xy, ncol = p-1, nrow = n), xy[,p])
}
imputed_list = list()
for (i in seq(m)) {
imputed_list = append(imputed_list, list(irmi(xy)[,1:p]))
}
return_list = list("imputed" = imputed_list,
"m" = m)
return(return_list)
}
fit <- function(xyList, ...) {
m = xyList$m
regression_list = list()
for (i in seq(m)) {
xy = xyList$imputed[[i]]
# Set last column to y
colnames(xy) = colnames(xy, do.NULL = FALSE)
colnames(xy)[ncol(xy)] = "y"
lmcontrol = lmrob.control(k.max = 1000)
regression_list = append(regression_list, list(lmrob(y ~ ., data = xy, control = lmcontrol)))
}
return_list = list("models" = regression_list,
"m" = m)
return(return_list)
}
pool <- function(fitList, ...) {
m = fitList$m
modelList = fitList$models
p = length(modelList[[1]]$coefficients)
n = length(modelList[[1]]$residuals)
# Pooled estimate and Pooled variance
coefficient_list = list()
covariance_list = list()
for (i in seq(m)) {
model = modelList[[i]]
if (!any(is.na(diag(model$cov)))) {
coefficient_list = append(coefficient_list, list(model$coefficients))
covariance_list = append(covariance_list, list(diag(model$cov)))
}
}
pooled_estimate = apply(matrix(unlist(coefficient_list), ncol = p, byrow = TRUE), 2, mean)
within_imputation_variance = apply(matrix(unlist(covariance_list), ncol = p, byrow = TRUE), 2, mean)
between_imputation_variance = diag(cov(matrix(unlist(coefficient_list), ncol = p, byrow = TRUE)))
pooled_variance = within_imputation_variance + ((m+1)/m)*between_imputation_variance
# Standard error and t-statistic
standard_error = c()
t_statistic = c()
for (i in seq(p)) {
standard_error = rbind(standard_error, sqrt(pooled_variance)[i])
t_statistic = rbind(t_statistic, pooled_estimate[i]/standard_error[i])
}
# Degrees of freedom and significance level
gamma = ((m+1)/m) * (between_imputation_variance/pooled_variance)
v_m = (m-1) / (gamma^2)
v_comp = n - p
v_obs = ((v_comp+1)/(v_comp+3))*v_comp*(1-gamma)
v_tilde = (v_m*v_obs)/(v_m+v_obs)
p_values = 2*pt(abs(t_statistic), v_tilde, lower.tail=FALSE)
summary_matrix = matrix(0, nrow = p, ncol = 5)
summary_matrix[,1] = pooled_estimate
summary_matrix[,2] = standard_error
summary_matrix[,3] = t_statistic
summary_matrix[,4] = v_tilde # Shouldn't it be an integer?
summary_matrix[,5] = p_values
return(summary_matrix)
}
bootstrap <- function(x, R = 100, k = 10, DDC = FALSE, ...) {
p = ncol(x)
n = nrow(x)
bootstrapped_estimates = list()
for (i in seq(R)) {
x_r = x[sample(seq(n), n, replace = TRUE),]
if (DDC == TRUE) {
indices = cellWise::DDC(x_r[,1:(p-1)], DDCpars = list("silent" = TRUE))$indall
vectorized_x_r = c(x_r[,1:(p-1)])
vectorized_x_r[indices] = NA
x_r = cbind(matrix(vectorized_x_r, ncol = p-1, nrow = n), x_r[,p])
}
x_r_imputed = kNN(data.frame(x_r), k = k)[,1:p]
# Set last column to y
colnames(x_r_imputed) = colnames(x_r_imputed, do.NULL = FALSE)
colnames(x_r_imputed)[ncol(x_r_imputed)] = "y"
lmcontrol = lmrob.control(k.max = 1000)
bootstrapped_estimates = append(bootstrapped_estimates, list(lmrob(y ~ ., data = data.frame(x_r_imputed), control = lmcontrol)$coefficients))
if (i == R) {
coefficient_matrix = matrix(unlist(bootstrapped_estimates), ncol = p, byrow = TRUE)
point_estimates = apply(coefficient_matrix, 2, mean)
standard_errors = sqrt(diag(cov(coefficient_matrix)))
}
}
z_statistic = point_estimates/standard_errors
p_values = 2*pnorm(abs(z_statistic), lower.tail=FALSE)
summary_matrix = matrix(0, nrow = p, ncol = 4)
summary_matrix[,1] = point_estimates
summary_matrix[,2] = standard_errors
summary_matrix[,3] = z_statistic
summary_matrix[,4] = p_values
return_list = list("replicates" = coefficient_matrix,
"summary" = summary_matrix)
return(return_list)
}
airquality[,2:]
airquality[,2]
airquality[,2:]
airquality[,-1]
airquality[,1]
bootstrap(airquality)
warnings()
library(VIM)
library(cellWise)
library(robustbase)
data("airquality")
multimp <- function(xy, m = 10, DDC = FALSE, ...) {
p = ncol(xy)
n = nrow(xy)
if (DDC == TRUE) {
indices = cellWise::DDC(xy[,1:(p-1)], DDCpars = list("silent" = TRUE))$indall
vectorized_xy = c(xy[,1:(p-1)])
vectorized_xy[indices] = NA
xy = cbind(matrix(vectorized_xy, ncol = p-1, nrow = n), xy[,p])
}
imputed_list = list()
for (i in seq(m)) {
imputed_list = append(imputed_list, list(irmi(xy)[,1:p]))
}
return_list = list("imputed" = imputed_list,
"m" = m)
return(return_list)
}
fit <- function(xyList, ...) {
m = xyList$m
regression_list = list()
for (i in seq(m)) {
xy = xyList$imputed[[i]]
# Set last column to y
colnames(xy) = colnames(xy, do.NULL = FALSE)
colnames(xy)[ncol(xy)] = "y"
lmcontrol = lmrob.control(k.max = 1000)
regression_list = append(regression_list, list(lmrob(y ~ ., data = xy, control = lmcontrol)))
}
return_list = list("models" = regression_list,
"m" = m)
return(return_list)
}
pool <- function(fitList, ...) {
m = fitList$m
modelList = fitList$models
p = length(modelList[[1]]$coefficients)
n = length(modelList[[1]]$residuals)
# Pooled estimate and Pooled variance
coefficient_list = list()
covariance_list = list()
for (i in seq(m)) {
model = modelList[[i]]
if (!any(is.na(diag(model$cov)))) {
coefficient_list = append(coefficient_list, list(model$coefficients))
covariance_list = append(covariance_list, list(diag(model$cov)))
}
}
pooled_estimate = apply(matrix(unlist(coefficient_list), ncol = p, byrow = TRUE), 2, mean)
within_imputation_variance = apply(matrix(unlist(covariance_list), ncol = p, byrow = TRUE), 2, mean)
between_imputation_variance = diag(cov(matrix(unlist(coefficient_list), ncol = p, byrow = TRUE)))
pooled_variance = within_imputation_variance + ((m+1)/m)*between_imputation_variance
# Standard error and t-statistic
standard_error = c()
t_statistic = c()
for (i in seq(p)) {
standard_error = rbind(standard_error, sqrt(pooled_variance)[i])
t_statistic = rbind(t_statistic, pooled_estimate[i]/standard_error[i])
}
# Degrees of freedom and significance level
gamma = ((m+1)/m) * (between_imputation_variance/pooled_variance)
v_m = (m-1) / (gamma^2)
v_comp = n - p
v_obs = ((v_comp+1)/(v_comp+3))*v_comp*(1-gamma)
v_tilde = (v_m*v_obs)/(v_m+v_obs)
p_values = 2*pt(abs(t_statistic), v_tilde, lower.tail=FALSE)
summary_matrix = matrix(0, nrow = p, ncol = 5)
summary_matrix[,1] = pooled_estimate
summary_matrix[,2] = standard_error
summary_matrix[,3] = t_statistic
summary_matrix[,4] = v_tilde # Shouldn't it be an integer?
summary_matrix[,5] = p_values
return(summary_matrix)
}
bootstrap <- function(x, R = 100, k = 10, DDC = FALSE, ...) {
p = ncol(x)
n = nrow(x)
bootstrapped_estimates = list()
for (i in seq(R)) {
x_r = x[sample(seq(n), n, replace = TRUE),]
if (DDC == TRUE) {
indices = cellWise::DDC(x_r[,1:(p-1)], DDCpars = list("silent" = TRUE))$indall
vectorized_x_r = c(x_r[,1:(p-1)])
vectorized_x_r[indices] = NA
x_r = cbind(matrix(vectorized_x_r, ncol = p-1, nrow = n), x_r[,p])
}
x_r_imputed = kNN(data.frame(x_r), k = k)[,1:p]
# Set last column to y
colnames(x_r_imputed) = colnames(x_r_imputed, do.NULL = FALSE)
colnames(x_r_imputed)[ncol(x_r_imputed)] = "y"
lmcontrol = lmrob.control(k.max = 1000)
bootstrapped_estimates = append(bootstrapped_estimates, list(lmrob(y ~ ., data = data.frame(x_r_imputed), control = lmcontrol)$coefficients))
if (i == R) {
coefficient_matrix = matrix(unlist(bootstrapped_estimates), ncol = p, byrow = TRUE)
point_estimates = apply(coefficient_matrix, 2, mean)
standard_errors = sqrt(diag(cov(coefficient_matrix)))
}
}
z_statistic = point_estimates/standard_errors
p_values = 2*pnorm(abs(z_statistic), lower.tail=FALSE)
summary_matrix = matrix(0, nrow = p, ncol = 4)
summary_matrix[,1] = point_estimates
summary_matrix[,2] = standard_errors
summary_matrix[,3] = z_statistic
summary_matrix[,4] = p_values
return_list = list("replicates" = coefficient_matrix,
"summary" = summary_matrix)
return(return_list)
}
set.seed(12345)
bootstrap(airquality, k = 5)
set.seed(12345)
bootstrap(airquality, k = 10)
bootstrap(airquality, k = 10)
set.seed(12345)
bootstrap(airquality, k = 5)$summary
help()
install.packages('devtools')
install.packages('devtools')
setwd('/Users/cavriends/Dropbox/ESE/MSc Econometrics/Thesis/Bayesian VARs/Code/Jupyter/rcode/')
library(vars)
library(BVAR)
library(MARX)
library(shrinkTVP)
library(parallel)
standardize <- function(data, train) {
standardized = c()
for (m in 1:dim(data)[2]) {
x = data[,m]
mean = mean(x[1:train])
std = sd(x[1:train])
standardized = cbind(standardized, (x - mean)/std)
}
return(standardized)
}
h_step_msfe <- function(h_step, y_pred, y_true, train) {
msfe_list = list()
for (h in 0:(h_step-1)) {
msfe_vec = c()
number_of_predictions = dim(y_true)[1] - train - h
for (i in 1:number_of_predictions) {
msfe = (y_pred[[i]][h+1,] - y_true[train+i+h,])^2
msfe_vec = rbind(msfe_vec, msfe)
}
msfe_list = append(msfe_list, mean(colMeans(msfe_vec)))
}
return(msfe_list)
}
var_ols <- function(T, M, p, train, y, h_steps, coeff) {
predict_list_var <- list()
for (i in train:(T - 1)) {
y_subset <- y[1:i, ]
var_fit <- VAR(y_subset, lag = p)
predict_result <- predict(var_fit, n.ahead = h_steps)$fcst
predictions <- c()
for (m in 1:M) {
predictions <- cbind(predictions, predict_result[[m]][, 1])
}
predict_list_var <- append(predict_list_var, list(predictions))
}
msfe_var <- h_step_msfe(h_steps, predict_list_var, y, train)
return(msfe_var)
}
var_ols_msd <- function(T, M, p, y, true_coeff) {
var_fit <- VAR(y, lag = p)
estimated_coeff <- c()
for (m in 1:M) {
estimated_coeff <- cbind(estimated_coeff, var_fit$varresult[[m]][[1]][1:M])
}
msd <- c()
for (i in 1:(T-1)) {
msd <- rbind(msd, mean(estimated_coeff - matrix(true_coeff[,i], nrow=M, ncol=M)^2))
}
final_msd <- mean(msd)
return(final_msd)
}
bvar_minnesota <- function(T, M, p, train, y, x, mcmc_iter, h_steps, coeff, print_status=FALSE) {
predict_list_bvar <- list()
mcmc_iter_bvar = mcmc_iter*5
for (i in train:(T - 1)) {
if (print_status) {
if (i %% 10 == 0) {
cat("\014")
print("Progress of B-VAR with Minnesota prior...")
}
print(sprintf("Progress %i/%i", i - train + 1, number_of_predictions))
}
y_subset <- y[1:i, ]
bvar_fit <- bvar(data = y_subset,
lags = p,
#priors = bv_priors(hyper = c("full")),
fcast = bv_fcast(h_steps),
verbose = FALSE,
n_draw = mcmc_iter_bvar,
n_burn = floor(mcmc_iter_bvar/2))
predict_result <- predict(bvar_fit)
predictions <- c()
for (h in 1:h_steps) {
predictions <- rbind(predictions, colMeans(predict_result$fcast[, h, ]))
}
predict_list_bvar <- append(predict_list_bvar, list(predictions))
}
msfe_bvar <- h_step_msfe(h_steps, predict_list_bvar, y, train)
return(msfe_bvar)
}
arx_ols <- function(T, M, p, train, y, x, h_steps, coeff) {
prediction_list <- list()
for (i in train:(T - 1)) {
prediction <- c()
for (m in 1:M) {
y_subset <- as.matrix(y[1:i,m])
x_subset <- as.matrix(x[1:i,])
if (m != 1) {
contemporaneous_y <- as.matrix(y[1:i,seq(m-1)])
x_complete <- cbind(x_subset, contemporaneous_y)
} else {
x_complete <- x_subset
}
arx_fit = arx.ls(y_subset, x_complete, p=0)
h_prediction <- c()
if (m != 1) {
for (h in 1:h_steps) {
h_prediction <- rbind(h_prediction, arx_fit$coefficients[2:(M+1+(m-1))] %*% t(cbind(as.matrix(x[i+h,]), as.matrix(y[i+h,seq(m-1)]))))
}
} else {
for (h in 1:h_steps) {
h_prediction <- rbind(h_prediction, arx_fit$coefficients[2:(M+1)] %*% t(as.matrix(x[i+h,])))
}
}
prediction <- cbind(prediction, h_prediction)
}
prediction_list <- append(prediction_list, list(prediction))
}
msfe_tvp_ols <- h_step_msfe(h_steps, prediction_list, y, train)
return(msfe_tvp_ols)
}
tvp_bar <- function(T, M, p, train, y, x, mcmc_iter, h_steps, coeff, print_status=FALSE) {
prediction_list_tvp <- list()
for (i in train:(T - 1)) {
if (print_status) {
if (i %% 10 == 0) {
cat("\014")
print("Progress of TVP-B-AR with Minnesota prior...")
}
print(sprintf("Progress %i/%i", i - train + 1, number_of_predictions))
}
prediction <- c()
for (m in 1:M) {
y_subset <- y[1:i,m]
x_subset <- x[1:i,]
if (m != 1) {
contemporaneous_y <- y[1:i,seq(m-1)]
x_complete <- cbind(x_subset, contemporaneous_y)
} else {
x_complete <- x_subset
}
data <- cbind(y_subset,x_complete)
tvp_fit <- shrinkTVP(y_subset ~ .,
data=data,
niter=mcmc_iter,
nburn=floor(mcmc_iter/2),
display_progress=FALSE)
beta_mean <- unlist(lapply(lapply(tvp_fit$beta, colMeans), tail, 1))
h_prediction <- c()
if (m != 1) {
for (h in 1:h_steps) {
h_prediction <- rbind(h_prediction, beta_mean[2:(M+1+(m-1))] %*% t(cbind(as.matrix(x[i+h,]), as.matrix(y[i+h,seq(m-1)]))))
}
} else {
for (h in 1:h_steps) {
h_prediction <- rbind(h_prediction, beta_mean[2:(M+1)] %*% t(as.matrix(x[i+h,])))
}
}
# for (h in 1:h_steps) {
#   h_prediction <- rbind(h_prediction, beta_mean[2:(M+1)] %*% t(as.matrix(x[i+h,])))
# }
prediction <- cbind(prediction, h_prediction)
}
prediction_list_tvp <- append(prediction_list_tvp, list(prediction))
}
msfe_tvp_bar <- h_step_msfe(h_steps, prediction_list_tvp, y, train)
return(msfe_tvp_bar)
}
simulation_run <- function(run) {
m = 5
T = 200
train <- T+1-50
number_of_predictions <- T - train
h_steps <- 8
p <- 1
mcmc_iter <- 1000
y_dgp <- read.csv(paste("../simulations/datasets/",paste('y',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
x_dgp <- read.csv(paste("../simulations/datasets/",paste('x',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
coeff <- read.csv(paste("../simulations/datasets/",paste('coefficients',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
## VAR-OLS ##
start_time = proc.time()
msfe_var_ols <- var_ols(T, m, p, train, y_dgp, h_steps)
msd_var_ols <- var_ols_msd(T, m, p, y_dgp, coeff)
print(paste("VAR -> DONE! | elapsed: ", round((proc.time() - start_time)[3],4), ' seconds | MSFE: ',  round(mean(unlist(msfe_var_ols)),4), sep=""))
## B-VAR with Minnesota prior ##
start_time = proc.time()
msfe_bvar_minnesota <- bvar_minnesota(T, m, p, train, y_dgp, x_dgp, mcmc_iter, h_steps)
print(paste("BVAR -> DONE! | elapsed: ", round((proc.time() - start_time)[3],4), ' seconds | MSFE: ',  round(mean(unlist(msfe_bvar_minnesota)),4), sep=""))
## ARX with OLS ##
start_time = proc.time()
msfe_arx_ols <- arx_ols(T, m, p, train, y_dgp, x_dgp, h_steps)
print(paste("AR-X -> DONE! | elapsed: ", round((proc.time() - start_time)[3],4), ' seconds | MSFE: ',  round(mean(unlist(msfe_arx_ols)),4), sep=""))
## TVP-B-AR with Minnesota prior ##
start_time = proc.time()
msfe_tvp_bar <- tvp_bar(T, m, p, train, y_dgp, x_dgp, mcmc_iter, h_steps)
print(paste("TVP-B-AR -> DONE! | elapsed: ", round((proc.time() - start_time)[3],4), ' seconds | MSFE: ',  round(mean(unlist(msfe_tvp_bar)),4), sep=""))
result_list <- list("msfe_var_ols" = msfe_var_ols,
"msfe_bvar_minnesota" = msfe_bvar_minnesota,
"msfe_arx_ols" = msfe_arx_ols,
"msfe_tvp_bar" = msfe_tvp_bar,
"msd_var_ols" = msd_var_ols)
return(result_list)
}
msfe_tvp_bar <- tvp_bar(T, m, p, train, y_dgp, x_dgp, mcmc_iter, h_steps)
m = 5
T = 200
train <- T+1-50
number_of_predictions <- T - train
h_steps <- 8
p <- 1
mcmc_iter <- 1000
y_dgp <- read.csv(paste("../simulations/datasets/",paste('y',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
run = 1
y_dgp <- read.csv(paste("../simulations/datasets/",paste('y',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
x_dgp <- read.csv(paste("../simulations/datasets/",paste('x',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
coeff <- read.csv(paste("../simulations/datasets/",paste('coefficients',m,T,p,run,sep="_"),'.csv', sep=""), header=FALSE)
msfe_tvp_bar <- tvp_bar(T, m, p, train, y_dgp, x_dgp, mcmc_iter, h_steps)
