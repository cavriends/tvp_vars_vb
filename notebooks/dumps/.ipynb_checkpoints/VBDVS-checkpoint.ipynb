{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Own code\n",
    "sys.path.append(\"../\")\n",
    "from utils.data_utils import create_data, create_dgp_data, transformation, standardize\n",
    "from utils.tvp_models import TVPVARModel\n",
    "\n",
    "# Suppress scientific notation in numpy\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Set RNG\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 39\n"
     ]
    }
   ],
   "source": [
    "train = 178 # 2005Q1\n",
    "\n",
    "M = 3\n",
    "p = 4\n",
    "T = train - p\n",
    "k = M*(M*p+1)\n",
    "\n",
    "print(f'k: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"../data/fred_qd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = True\n",
    "\n",
    "gdp = transformation(ds[\"GDPC1\"].iloc[2:].to_numpy(), 5, transform, scale=1)\n",
    "cpi = transformation(ds[\"CPIAUCSL\"].iloc[2:].to_numpy(), 6, transform, scale=1)\n",
    "fedfund = transformation(ds[\"FEDFUNDS\"].iloc[2:].to_numpy(), 2, transform, scale=1)\n",
    "compi = transformation(ds[\"PPIACO\"].iloc[2:].to_numpy(), 6, transform, scale=1)\n",
    "borrowings = transformation(ds[\"TOTRESNS\"].iloc[2:].to_numpy(), 6, transform, scale=1)\n",
    "sp500 = transformation(ds[\"S&P 500\"].iloc[2:].to_numpy(), 5, transform, scale=1)\n",
    "m2 = transformation(ds[\"M2REAL\"].iloc[2:].to_numpy(), 5, transform, scale=1)\n",
    "\n",
    "# Start due to transformation\n",
    "\n",
    "lag = 2\n",
    "\n",
    "series_total = [gdp[lag:], cpi[lag:], fedfund[lag:]]\n",
    "# series_total = [gdp[lag:], cpi[lag:], fedfund[lag:], compi[lag:], borrowings[lag:], sp500[lag:], m2[lag:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_series = standardize(series_total, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVP-VAR with Variational Bayes (VB) - M = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_T = len(gdp[lag:])\n",
    "X_complete, y_complete = create_data(series_total,\n",
    "                                     complete_T,\n",
    "                                     complete_T-p,\n",
    "                                     M,\n",
    "                                     p,\n",
    "                                     k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVSS\n",
    "# Optimizing the shrinkage for M = 7 (default values are optimal for M = 3)\n",
    "\n",
    "# tau_0 = np.arange(0.5, 5, 1)\n",
    "# tau_1 = np.arange(100, 300, 50)\n",
    "\n",
    "tau_0 = np.arange(0.5, 5, 1)\n",
    "tau_1 = np.arange(10, 100, 15)\n",
    "\n",
    "train_gridsearch = 98 #1985Q4\n",
    "\n",
    "parameter_set = []\n",
    "\n",
    "for t_0 in tau_0:\n",
    "    for t_1 in tau_1:\n",
    "        parameter_set.append((t_0, t_1))\n",
    "\n",
    "msfe_list = []\n",
    "number_of_possibilities = len(parameter_set)\n",
    "print(f'Number of possibilities: {number_of_possibilities}')\n",
    "\n",
    "for idx, p_set in enumerate(parameter_set):\n",
    "    \n",
    "    tau_0, tau_1 = p_set\n",
    "    \n",
    "    tvp_svss = TVPVARModel(X_complete, y_complete, p, train)\n",
    "    tvp_svss.initialize_priors(prior='svss',\n",
    "                               prior_parameters={'tau_0': tau_0,\n",
    "                                                 'tau_1': tau_1,\n",
    "                                                 'pi0': 0.5},\n",
    "                               )\n",
    "    \n",
    "    mt1t, St1t = tvp_svss.train(print_status=False)\n",
    "    msfe_list.append(tvp_svss.insample_msfe())\n",
    "    \n",
    "    print(f'Progress: {(idx+1)}/{number_of_possibilities}')\n",
    "    \n",
    "# Clear printing output\n",
    "clear_output()\n",
    "    \n",
    "sorted_indices = np.argsort(msfe_list)\n",
    "\n",
    "for i in range(number_of_possibilities):\n",
    "    \n",
    "    sorted_index = sorted_indices[i]\n",
    "    \n",
    "    print(f'MSFE: {msfe_list[sorted_index]} | '\n",
    "          f'tau_0: {parameter_set[sorted_index][0]} & '\n",
    "          f'tau_1: {parameter_set[sorted_index][1]}')\n",
    "    \n",
    "    \n",
    "optimal_svss = parameter_set[sorted_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horseshoe\n",
    "# Optimizing the shrinkage for M = 7 (default values are optimal for M = 3)\n",
    "\n",
    "a0_horseshoe = np.arange(10, 30, 5)\n",
    "b0_horseshoe = np.arange(10, 30, 5)\n",
    "\n",
    "train_gridsearch = 98 # 1985Q1\n",
    "\n",
    "parameter_set = []\n",
    "\n",
    "for a0 in a0_horseshoe:\n",
    "    for b0 in b0_horseshoe:\n",
    "        parameter_set.append((a0, b0))\n",
    "\n",
    "msfe_list = []\n",
    "number_of_possibilities = len(parameter_set)\n",
    "print(f'Number of possibilities: {number_of_possibilities}')\n",
    "\n",
    "for idx, p_set in enumerate(parameter_set):\n",
    "    \n",
    "    a0, b0 = p_set\n",
    "    \n",
    "    tvp_horseshoe = TVPVARModel(X_complete, y_complete, p, train_gridsearch)\n",
    "    tvp_horseshoe.initialize_priors(prior='horseshoe',\n",
    "                               prior_parameters={'a0': a0,\n",
    "                                                 'b0': b0})\n",
    "    \n",
    "    mt1t, St1t = tvp_horseshoe.train(print_status=False)\n",
    "    msfe_list.append(tvp_horseshoe.insample_msfe())\n",
    "    \n",
    "    print(f'Progress: {(idx+1)}/{number_of_possibilities}')\n",
    "    \n",
    "# Clear printing output\n",
    "clear_output()\n",
    "    \n",
    "sorted_indices = np.argsort(msfe_list)\n",
    "\n",
    "for i in range(number_of_possibilities):\n",
    "    \n",
    "    sorted_index = sorted_indices[i]\n",
    "    \n",
    "    print(f'MSFE: {msfe_list[sorted_index]} | '\n",
    "          f'a0: {parameter_set[sorted_index][0]} & '\n",
    "          f'b0: {parameter_set[sorted_index][1]}')\n",
    "    \n",
    "optimal_horseshoe = parameter_set[sorted_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "# Optimizing the shrinkage for M = 7 (default values are optimal for M = 3)\n",
    "\n",
    "lambda_parameters = np.arange(10, 200, 25)\n",
    "\n",
    "train_gridsearch = 98 #1985Q4\n",
    "\n",
    "parameter_set = []\n",
    "\n",
    "for lambda_param in lambda_parameters:\n",
    "    parameter_set.append((lambda_param))\n",
    "\n",
    "msfe_list = []\n",
    "number_of_possibilities = len(parameter_set)\n",
    "print(f'Number of possibilities: {number_of_possibilities}')\n",
    "\n",
    "for idx, p_set in enumerate(parameter_set):\n",
    "    \n",
    "    lambda_param = p_set\n",
    "    \n",
    "    tvp_lasso = TVPVARModel(X_complete, y_complete, p, train_gridsearch)\n",
    "    tvp_lasso.initialize_priors(prior='lasso',\n",
    "                               prior_parameters={'lambda_param': lambda_param})\n",
    "    \n",
    "    mt1t, St1t = tvp_lasso.train(print_status=False)\n",
    "    msfe_list.append(tvp_lasso.insample_msfe())\n",
    "    \n",
    "    print(f'Progress: {(idx+1)}/{number_of_possibilities}')\n",
    "    \n",
    "# Clear printing output\n",
    "clear_output()\n",
    "    \n",
    "sorted_indices = np.argsort(msfe_list)\n",
    "\n",
    "for i in range(number_of_possibilities):\n",
    "    \n",
    "    sorted_index = sorted_indices[i]\n",
    "    \n",
    "    print(f'MSFE: {msfe_list[sorted_index]} | '\n",
    "          f'lambda: {parameter_set[sorted_index]}')\n",
    "    \n",
    "optimal_lambda = parameter_set[sorted_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVSS\n",
    "# Calculate h-step forecasts (h = 1 .. 8) for M = 7\n",
    "\n",
    "# optimal_svss = (4.5, 250) #M = 7\n",
    "optimal_svss = (1.5, 70)\n",
    "\n",
    "tvp_svss = TVPVARModel(X_complete, y_complete, p, train)\n",
    "tvp_svss.initialize_priors(prior='svss',\n",
    "                           prior_parameters={'tau_0': optimal_svss[0],\n",
    "                                             'tau_1': optimal_svss[1],\n",
    "                                             'pi0':0.5})\n",
    "\n",
    "h_forecast = 8\n",
    "\n",
    "msfe_svss, alpl_svss = tvp_svss.calculate_metrics(h_forecast)\n",
    "\n",
    "clear_output()\n",
    "print(f'MSFE for SVSS:')\n",
    "print(np.mean(msfe_svss,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horseshoe\n",
    "# Calculate h-step forecasts (h = 1 .. 8) for M = 7\n",
    "\n",
    "optimal_horseshoe = (25,10)\n",
    "\n",
    "tvp_horseshoe = TVPVARModel(X_complete, y_complete, p, train)\n",
    "tvp_horseshoe.initialize_priors(prior='horseshoe',\n",
    "                            prior_parameters={'a0': optimal_horseshoe[0],\n",
    "                                              'b0': optimal_horseshoe[1]})\n",
    "\n",
    "tvp_horseshoe.print_status = False\n",
    "\n",
    "h_forecast = 8\n",
    "\n",
    "msfe_horseshoe, alpl_horseshoe = tvp_horseshoe.calculate_metrics(h_forecast)\n",
    "\n",
    "clear_output()\n",
    "print(f'MSFE for Horseshoe:')\n",
    "print(np.mean(msfe_horseshoe,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    \n",
    "    np.savetxt(f'../rcode/horseshoe_{i+1}.csv', tvp_horseshoe.y_pred[:,:,i], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp_svss = TVPVARModel(X_complete, y_complete, p, train, 200)\n",
    "tvp_svss.initialize_priors(prior='horseshoe')\n",
    "__, __ = tvp_svss.train(print_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "# Calculate h-step forecasts (h = 1 .. 8) for M = 7\n",
    "\n",
    "tvp_lasso = TVPVARModel(X_complete, y_complete, p, train)\n",
    "tvp_lasso.initialize_priors(prior='lasso',\n",
    "                            prior_parameters={'lambda_param': optimal_lambda})\n",
    "\n",
    "h_forecast = 8\n",
    "\n",
    "msfe_lasso, alpl_lasso = tvp_lasso.calculate_metrics(h_forecast)\n",
    "\n",
    "clear_output()\n",
    "np.mean(msfe_lasso, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp = TVPVARModel(X_complete, y_complete, p, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dump_to_disk = (msfe_horseshoe, alpl_horseshoe, msfe_lasso,\n",
    "                alpl_lasso, optimal_svss, optimal_horseshoe, optimal_lambda)\n",
    "\n",
    "with open('dumps/mse_alpl_7_non_standard_horseshoe_lasso.pkl', 'wb') as f:\n",
    "    pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(msfe_horseshoe,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dump_to_disk = (msfe_horseshoe, alpl_horseshoe, optimal_horseshoe)\n",
    "\n",
    "with open('dumps/mse_alpl_7_non_standard_horseshoe.pkl', 'wb') as f:\n",
    "    pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVSS\n",
    "# Calculate h-step forecasts (h = 1 .. 8) for M = 7\n",
    "\n",
    "# optimal_svss = (4.5, 250) #M = 7\n",
    "optimal_svss = (1.5, 70)\n",
    "\n",
    "tvp_svss = TVPVARModel(X_complete, y_complete, p, train)\n",
    "tvp_svss.initialize_priors(prior='svss',\n",
    "                           prior_parameters={'tau_0': optimal_svss[0],\n",
    "                                             'tau_1': optimal_svss[1],\n",
    "                                             'pi0':0.5})\n",
    "\n",
    "h_forecast = 1\n",
    "\n",
    "msfe_svss, alpl_svss = tvp_svss.calculate_metrics(h_forecast)\n",
    "\n",
    "clear_output()\n",
    "print(f'MSFE for SVSS:')\n",
    "print(np.mean(msfe_svss,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_svss_tau_0(parameter_values, h_forecast):\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    tvp_plus = TVPVARModel(X_complete, y_complete, p, train)\n",
    "    tvp_minus = TVPVARModel(X_complete, y_complete, p, train)\n",
    "    \n",
    "    tvp_plus.initialize_priors(prior='svss', prior_parameters={'tau_0':parameter_values['tau_0']+error,'tau_1':parameter_values['tau_1'],'pi0':parameter_values['pi0']})\n",
    "    tvp_minus.initialize_priors(prior='svss', prior_parameters={'tau_0':parameter_values['tau_0']-error,'tau_1':parameter_values['tau_1'],'pi0':parameter_values['pi0']})\n",
    "    \n",
    "    msfe_svss_plus, __ = tvp_plus.calculate_metrics(h_forecast, print_status=False)\n",
    "    msfe_svss_minus, __ = tvp_minus.calculate_metrics(h_forecast, print_status=False)\n",
    "    \n",
    "    derivative = (msfe_svss_plus[0][0] - msfe_svss_minus[0][0])/(2*error)\n",
    "    print(f'plus: {msfe_svss_plus[0][0]} | minus: {msfe_svss_minus[0][0]}')\n",
    "    \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tau_0_set = np.arange(1.5,10,0.25)\n",
    "\n",
    "derivatives = np.zeros(tau_0_set.shape[0], dtype=np.float64)\n",
    "\n",
    "for i, tau_0 in enumerate(tau_0_set):\n",
    "    \n",
    "    derivatives[i] = calculate_derivative_svss_tau_0({'tau_0':tau_0,'tau_1':70,'pi0':0.5}, 1)\n",
    "    print(f'{i+1}/{tau_0_set.shape[0]} - derivative: {derivatives[i]}')\n",
    "    \n",
    "dump_to_disk = (tau_0_set, derivatives)\n",
    "    \n",
    "with open('dumps/derivatives_svss_tau_0.pkl', 'wb') as f:\n",
    "    pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_svss_tau_1(parameter_values, h_forecast):\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    tvp_plus = TVPVARModel(X_complete, y_complete, p, train)\n",
    "    tvp_minus = TVPVARModel(X_complete, y_complete, p, train)\n",
    "    \n",
    "    tvp_plus.initialize_priors(prior='svss', prior_parameters={'tau_0':parameter_values['tau_0'],'tau_1':parameter_values['tau_1']+error,'pi0':parameter_values['pi0']})\n",
    "    tvp_minus.initialize_priors(prior='svss', prior_parameters={'tau_0':parameter_values['tau_0'],'tau_1':parameter_values['tau_1']-error,'pi0':parameter_values['pi0']})\n",
    "    \n",
    "    msfe_svss_plus, __ = tvp_plus.calculate_metrics(h_forecast, print_status=False)\n",
    "    msfe_svss_minus, __ = tvp_minus.calculate_metrics(h_forecast, print_status=False)\n",
    "    \n",
    "    derivative = (msfe_svss_plus[0][0] - msfe_svss_minus[0][0])/(2*error)\n",
    "    print(f'plus: {msfe_svss_plus[0][0]} | minus: {msfe_svss_minus[0][0]}')\n",
    "    \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pickle\n",
    "\n",
    "tau_1_set = np.arange(70,80,0.25)\n",
    "\n",
    "derivatives = np.zeros(tau_1_set.shape[0], dtype=np.float64)\n",
    "\n",
    "for i, tau_1 in enumerate(tau_1_set):\n",
    "    derivatives[i] = calculate_derivative_svss_tau_1({'tau_0':1.5,'tau_1':tau_1,'pi0':0.5}, 1)\n",
    "    print(f'{i+1}/{tau_1_set.shape[0]} - derivative: {derivatives[i]}')\n",
    "    \n",
    "dump_to_disk = (tau_1_set, derivatives)\n",
    "    \n",
    "with open('dumps/derivatives_svss_tau_1.pkl', 'wb') as f:\n",
    "    pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp = TVPVARModel(X_complete, y_complete, p, train)\n",
    "tvp.initialize_priors(prior='svss', prior_parameters={'tau_0':2.5,'tau_1':100, 'pi0':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005257996901390391"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvp.insample_msfe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005257996901390391"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvp.insample_msfe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp.prior_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivatives(prior, pior_parameters, parameter_id, h_forecast):\n",
    "    \n",
    "    msfe_list = []\n",
    "    error = np.sqrt(1.1e-16)\n",
    "    for i in range(2):\n",
    "        changed_parameter = pior_parameters.get(parameter_id)\n",
    "        if i == 0:\n",
    "            changed_parameter += error\n",
    "        else:\n",
    "            changed_parameter -= error\n",
    "        pior_parameters.pop(parameter_id)\n",
    "        pior_parameters.update({parameter_id: changed_parameter})\n",
    "        tvp = TVPVARModel(X_complete, y_complete, p, train)\n",
    "        tvp.initialize_priors(prior=prior, prior_parameters=pior_parameters)\n",
    "        msfe, __ = tvp.calculate_metrics(h_forecast, print_status=False)\n",
    "        msfe_list.append(msfe[0])\n",
    "        \n",
    "    derivative = (msfe_list[0] - msfe_list[1])/(2*error)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/tvp_models.py:207: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  gamma = 1 / (np.multiply(1 + (np.divide((1 - self.pi0), self.pi0)), np.exp(l_0 - l_1)))\n",
      "../utils/tvp_models.py:207: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gamma = 1 / (np.multiply(1 + (np.divide((1 - self.pi0), self.pi0)), np.exp(l_0 - l_1)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tau_0_set = np.arange(1.5,10,0.25)\n",
    "\n",
    "derivatives = np.zeros(tau_0_set.shape[0], dtype=np.float64)\n",
    "\n",
    "for i, tau_0 in enumerate(tau_0_set):\n",
    "    \n",
    "    derivatives[i] = calculate_derivatives(h_forecast=1,\n",
    "                                           prior_parameters={'tau_0':tau_0,'tau_1':70,'pi0':0.5},\n",
    "                                           parameter_id='tau_0',\n",
    "                                           prior='svss')\n",
    "    print(f'{i+1}/{tau_0_set.shape[0]} - derivative: {derivatives[i]}')\n",
    "    \n",
    "dump_to_disk = (tau_0_set, derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
