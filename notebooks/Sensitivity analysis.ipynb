{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy import io\n",
    "import pickle\n",
    "\n",
    "# Own code\n",
    "sys.path.append(\"../\")\n",
    "from utils.data_utils import generate_contemp_matrices, transformation, standardize\n",
    "from utils.tvp_models import TVPVARModel, tvp_ar_contemp, tvp_ar_non_contemp\n",
    "\n",
    "# Suppress scientific notation in numpy\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set M and standardization\n",
    "\n",
    "M = 3\n",
    "standardization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = True\n",
    "\n",
    "ds = pd.read_csv(\"../data/fred_qd.csv\")\n",
    "gdp = transformation(ds[\"GDPC1\"].iloc[2:].to_numpy(), 5, transform, scale=1)\n",
    "cpi = transformation(ds[\"CPIAUCSL\"].iloc[2:].to_numpy(), 6, transform, scale=1)\n",
    "fedfund = transformation(ds[\"FEDFUNDS\"].iloc[2:].to_numpy(), 2, transform, scale=1)\n",
    "compi = transformation(ds[\"PPIACO\"].iloc[2:].to_numpy(), 6, transform, scale=1)\n",
    "borrowings = transformation(ds[\"TOTRESNS\"].iloc[2:].to_numpy(), 6, transform, scale=1)\n",
    "sp500 = transformation(ds[\"S&P 500\"].iloc[2:].to_numpy(), 5, transform, scale=1)\n",
    "m2 = transformation(ds[\"M2REAL\"].iloc[2:].to_numpy(), 5, transform, scale=1)\n",
    "\n",
    "# Start due to transformation\n",
    "\n",
    "lag = 1\n",
    "\n",
    "if M == 3:\n",
    "\n",
    "    series = [gdp[lag:], cpi[lag:], fedfund[lag:]]\n",
    "    \n",
    "elif M == 7:\n",
    "    \n",
    "    series = [gdp[lag:], cpi[lag:], fedfund[lag:],compi[lag:],borrowings[lag:],sp500[lag:],m2[lag:]]\n",
    "    \n",
    "\n",
    "if standardization:\n",
    "    \n",
    "    series = standardize(series, train = 243-25)\n",
    "\n",
    "series_total = np.array(series)\n",
    "\n",
    "y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(244, M, 1, series_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model, given the specific data, converges at all\n",
    "\n",
    "T = 243\n",
    "p = 1\n",
    "prior = \"lasso_alternative\"\n",
    "train = T - 25\n",
    "\n",
    "msfe, alpl, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=True, iterations=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter -> $a_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_lasso_a0(iteration, parameter_value):\n",
    "    \n",
    "    prior = \"lasso_alternative\"\n",
    "    T = 243\n",
    "    p = 1\n",
    "    train = T-25\n",
    "    iterations = 100\n",
    "\n",
    "    error = np.sqrt(1.1e-16)\n",
    "    prior_parameters_plus = {\"a0_lasso\":parameter_value+error,\"b0_lasso\":1e-3}\n",
    "    prior_parameters_minus = {\"a0_lasso\":parameter_value-error,\"b0_lasso\":1e-3}\n",
    "    \n",
    "    msfe_plus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_plus)\n",
    "    msfe_minus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_minus)\n",
    "    \n",
    "    derivative = (msfe_plus.mean() - msfe_minus.mean())/(2*error)\n",
    "    \n",
    "    print(f'Run: {iteration+1} -> Derivative: {derivative}')\n",
    "    \n",
    "    return [parameter_value, derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)\n",
    "\n",
    "start = 1e-3\n",
    "finish = 2\n",
    "interval = 64\n",
    "\n",
    "a0_set = [(i,value) for i, value in enumerate(np.linspace(start, finish, interval))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.starmap(calculate_derivative_lasso_a0, a0_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "result = np.block(derivatives)\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(result[:,0].min(), result[:,0].max(), 256) \n",
    "\n",
    "spl = make_interp_spline(result[:,0], result[:,1], k=3)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = \"lasso_alternative\"\n",
    "parameter = \"a0_lasso\"\n",
    "\n",
    "dump_to_disk = [derivatives, [xnew, power_smooth]]\n",
    "\n",
    "with open(f'../sensitivity/results_{M}_{prior}_{parameter}_{start}_{finish}_{interval}.pkl\"', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter -> $b_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_lasso_b0(iteration, parameter_value):\n",
    "    \n",
    "    prior = \"lasso_alternative\"\n",
    "    T = 243\n",
    "    p = 1\n",
    "    train = T-25\n",
    "    iterations = 75\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    prior_parameters_plus = {\"a0_lasso\":1e-3,\"b0_lasso\":parameter_value+error}\n",
    "    prior_parameters_minus = {\"a0_lasso\":1e-3,\"b0_lasso\":parameter_value-error}\n",
    "    \n",
    "    msfe_plus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_plus)\n",
    "    msfe_minus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_minus)\n",
    "    \n",
    "    derivative = (msfe_plus.mean() - msfe_minus.mean())/(2*error)\n",
    "    \n",
    "    print(f'Run: {iteration+1} -> Derivative: {derivative}')\n",
    "    \n",
    "    return [parameter_value, derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)\n",
    "\n",
    "start = 1e-3\n",
    "finish = 0.5\n",
    "interval = 64\n",
    "\n",
    "b0_set = [(i,value) for i, value in enumerate(np.linspace(start, finish, interval))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.starmap(calculate_derivative_lasso_b0, b0_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "result = np.block(derivatives)\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(result[:,0].min(), result[:,0].max(), 528) \n",
    "\n",
    "spl = make_interp_spline(result[:,0], result[:,1], k=3)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = \"lasso_alternative\"\n",
    "parameter = \"b0_lasso\"\n",
    "start = 1e-3\n",
    "finish = 0.5\n",
    "interval = 64\n",
    "\n",
    "dump_to_disk = [derivatives, [xnew, power_smooth]]\n",
    "\n",
    "with open(f'../sensitivity/results_{M}_{prior}_{parameter}_{start}_{finish}_{interval}.pkl\"', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model, given the specific data, converges at all\n",
    "\n",
    "T = 243\n",
    "p = 1\n",
    "prior = \"svss\"\n",
    "\n",
    "train = T - 25\n",
    "\n",
    "prior_paramters = {\"g0\":1e-2,\"h0\":1e-2,\"pi0\":0.5}\n",
    "\n",
    "msfe, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=True, iterations=75, prior_parameters=prior_paramters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter -> $g_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_svss_g0(iteration, parameter_value):\n",
    "    \n",
    "    prior = \"svss\"\n",
    "    T = 243\n",
    "    p = 1\n",
    "    train = T-25\n",
    "    iterations = 75\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    prior_parameters_plus = {\"g0\":parameter_value+error,\"h0\":1e-2, \"pi0\":0.5}\n",
    "    prior_parameters_minus = {\"g0\":parameter_value-error,\"h0\":1e-2, \"pi0\":0.5}\n",
    "    \n",
    "    msfe_plus, alpl_plus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_plus)\n",
    "    msfe_minus, apl_min, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_minus)\n",
    "    \n",
    "    derivative = (msfe_plus.mean() - msfe_minus.mean())/(2*error)\n",
    "    \n",
    "    print(f'Run: {iteration+1} -> Derivative: {derivative}')\n",
    "    \n",
    "    return [parameter_value, derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)\n",
    "\n",
    "start = 1e-2\n",
    "finish = 1\n",
    "interval = 64\n",
    "\n",
    "g0_set = [(i,value) for i, value in enumerate(np.linspace(start, finish, interval))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.starmap(calculate_derivative_svss_g0, g0_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "# Visualise the result\n",
    "\n",
    "result = np.block(derivatives)\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(result[:,0].min(), result[:,0].max(), 528) \n",
    "\n",
    "spl = make_interp_spline(result[:,0], result[:,1], k=3)  # type: BSpline+\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = \"svss\"\n",
    "parameter = \"g0\"\n",
    "\n",
    "dump_to_disk = [derivatives, [xnew, power_smooth]]\n",
    "\n",
    "with open(f'../sensitivity/results_{M}_{prior}_{parameter}_{start}_{finish}_{interval}_std.pkl\"', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter -> $h_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_svss_h0(iteration, parameter_value):\n",
    "    \n",
    "    prior = \"svss\"\n",
    "    T = 243\n",
    "    p = 1\n",
    "    train = T-25\n",
    "    iterations = 75\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    prior_parameters_plus = {\"g0\":1e-2,\"h0\":parameter_value+error, \"pi0\":0.5}\n",
    "    prior_parameters_minus = {\"g0\":1e-2,\"h0\":parameter_value-error, \"pi0\":0.5}\n",
    "    \n",
    "    msfe_plus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_plus)\n",
    "    msfe_minus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_minus)\n",
    "    \n",
    "    derivative = (msfe_plus.mean() - msfe_minus.mean())/(2*error)\n",
    "    \n",
    "    print(f'Run: {iteration+1} -> Derivative: {derivative}')\n",
    "    \n",
    "    return [parameter_value, derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)\n",
    "\n",
    "start = 1e-2\n",
    "finish = 1.5e-2\n",
    "interval = 64\n",
    "\n",
    "h0_set = [(i,value) for i, value in enumerate(np.linspace(start, finish, interval))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.starmap(calculate_derivative_svss_h0, h0_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[44,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "# Visualise the result\n",
    "\n",
    "threshold = 64\n",
    "\n",
    "result = np.block(derivatives)\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(result[:threshold,0].min(), result[:threshold,0].max(), 528)\n",
    "\n",
    "spl = make_interp_spline(result[:threshold,0], result[:threshold,1], k=3)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = \"svss\"\n",
    "parameter = \"h0\"\n",
    "\n",
    "dump_to_disk = [derivatives, [xnew, power_smooth]]\n",
    "\n",
    "with open(f'../sensitivity/results_{M}_{prior}_{parameter}_{start}_{finish}_{interval}_std.pkl\"', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horseshoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model, given the specific data, converges at all\n",
    "\n",
    "T = 243\n",
    "p = 1\n",
    "prior = \"horseshoe\"\n",
    "train = T - 25\n",
    "\n",
    "prior_parameters = {\"a0\":5, \"b0\":1}\n",
    "\n",
    "msfe, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=True, iterations=100, prior_parameters=prior_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter -> $a_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_horseshoe_a0(iteration, parameter_value):\n",
    "    \n",
    "    prior = \"horseshoe\"\n",
    "    T = 243\n",
    "    p = 1\n",
    "    train = T-25\n",
    "    iterations = 100\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    prior_parameters_plus = {\"a0\":parameter_value+error,\"b0\":1}\n",
    "    prior_parameters_minus = {\"a0\":parameter_value-error,\"b0\":1}\n",
    "    \n",
    "    msfe_plus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_plus)\n",
    "    msfe_minus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_minus)\n",
    "    \n",
    "    derivative = (msfe_plus.mean() - msfe_minus.mean())/(2*error)\n",
    "    \n",
    "    print(f'Run: {iteration+1} -> Derivative: {derivative}')\n",
    "    \n",
    "    return [parameter_value, derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 31 -> Derivative: 1.6597911857792504e-05\n",
      "Run: 29 -> Derivative: 1.2883206874616918e-05\n",
      "Run: 27 -> Derivative: 9.040730859805764e-06\n",
      "Run: 25 -> Derivative: 5.063785137914076e-06\n",
      "Run: 23 -> Derivative: 9.4732502743391e-07\n",
      "Run: 21 -> Derivative: -3.318242636469507e-06\n",
      "Run: 19 -> Derivative: -7.735812343185977e-06\n",
      "Run: 15 -> Derivative: -1.705176779411353e-05\n",
      "Run: 13 -> Derivative: -2.1963798988305103e-05\n",
      "Run: 17 -> Derivative: -1.2312661666038432e-05\n",
      "Run: 9 -> Derivative: -3.233558146893573e-05\n",
      "Run: 11 -> Derivative: -2.7056115521632946e-05\n",
      "Run: 7 -> Derivative: -3.784635846833215e-05\n",
      "Run: 5 -> Derivative: -4.352882003839229e-05\n",
      "Run: 3 -> Derivative: -4.942191773633318e-05\n",
      "Run: 1 -> Derivative: -5.553722951971405e-05\n",
      "Run: 30 -> Derivative: 1.4757843602846675e-05\n",
      "Run: 32 -> Derivative: 1.8408042822478095e-05\n",
      "Run: 28 -> Derivative: 1.0979211754004879e-05\n",
      "Run: 26 -> Derivative: 7.069666285047161e-06\n",
      "Run: 24 -> Derivative: 3.0237490159813224e-06\n",
      "Run: 22 -> Derivative: -1.1658176265155677e-06\n",
      "Run: 20 -> Derivative: -5.508874906368838e-06\n",
      "Run: 14 -> Derivative: -1.9485537172756262e-05\n",
      "Run: 16 -> Derivative: -1.4661002257833571e-05\n",
      "Run: 18 -> Derivative: -1.0002445634491836e-05\n",
      "Run: 10 -> Derivative: -2.9671824233348976e-05\n",
      "Run: 8 -> Derivative: -3.507889581289362e-05\n",
      "Run: 12 -> Derivative: -2.448713213863801e-05\n",
      "Run: 6 -> Derivative: -4.0660215653704374e-05\n",
      "Run: 4 -> Derivative: -4.644836743634072e-05\n",
      "Run: 2 -> Derivative: -5.245120763200355e-05\n",
      "Run: 37 -> Derivative: 2.701881795835292e-05\n",
      "Run: 61 -> Derivative: 5.9896165141362814e-05\n",
      "Run: 53 -> Derivative: 5.029439953811649e-05\n",
      "Run: 59 -> Derivative: 5.7603150646761325e-05\n",
      "Run: 51 -> Derivative: 4.7700275447278695e-05\n",
      "Run: 55 -> Derivative: 5.280466613634686e-05\n",
      "Run: 35 -> Derivative: 2.366005247042618e-05\n",
      "Run: 33 -> Derivative: 2.0188401896297143e-05\n",
      "Run: 57 -> Derivative: 5.523901441286755e-05\n",
      "Run: 49 -> Derivative: 4.5018903176262574e-05\n",
      "Run: 63 -> Derivative: 6.212004268939645e-05\n",
      "Run: 39 -> Derivative: 3.026990844097901e-05\n",
      "Run: 47 -> Derivative: 4.224920762900905e-05\n",
      "Run: 45 -> Derivative: 3.939515839096701e-05\n",
      "Run: 43 -> Derivative: 3.6457334360014394e-05\n",
      "Run: 41 -> Derivative: 3.341489521254463e-05\n",
      "Run: 62 -> Derivative: 6.1016828733397465e-05\n",
      "Run: 60 -> Derivative: 5.87580519132925e-05\n",
      "Run: 64 -> Derivative: 6.320713020450939e-05\n",
      "Run: 54 -> Derivative: 5.156160699297199e-05\n",
      "Run: 56 -> Derivative: 5.4028538950052174e-05\n",
      "Run: 52 -> Derivative: 4.900759225510718e-05\n",
      "Run: 58 -> Derivative: 5.6429972747225974e-05\n",
      "Run: 50 -> Derivative: 4.637220101554049e-05\n",
      "Run: 38 -> Derivative: 2.865825674873702e-05\n",
      "Run: 48 -> Derivative: 4.364873459882696e-05\n",
      "Run: 46 -> Derivative: 4.083330611921456e-05\n",
      "Run: 40 -> Derivative: 3.1854517332350566e-05\n",
      "Run: 36 -> Derivative: 2.5352915264976345e-05\n",
      "Run: 44 -> Derivative: 3.793774163335306e-05\n",
      "Run: 42 -> Derivative: 3.494880918974621e-05\n",
      "Run: 34 -> Derivative: 2.19387409801591e-05\n",
      "Run: 65 -> Derivative: 6.427726428176777e-05\n",
      "Run: 67 -> Derivative: 6.637014550998864e-05\n",
      "Run: 77 -> Derivative: 7.596107745294742e-05\n",
      "Run: 79 -> Derivative: 7.771141653680937e-05\n",
      "Run: 69 -> Derivative: 6.840174626284253e-05\n",
      "Run: 81 -> Derivative: 7.940891051438322e-05\n",
      "Run: 71 -> Derivative: 7.037239733911689e-05\n",
      "Run: 73 -> Derivative: 7.230219476514658e-05\n",
      "Run: 75 -> Derivative: 7.415880295946272e-05\n",
      "Run: 83 -> Derivative: 8.105736357172413e-05\n",
      "Run: 85 -> Derivative: 8.26542120182297e-05\n",
      "Run: 95 -> Derivative: 8.99575876465792e-05\n",
      "Run: 87 -> Derivative: 8.420607182964806e-05\n",
      "Run: 93 -> Derivative: 8.858096849278916e-05\n",
      "Run: 91 -> Derivative: 8.71697808657152e-05\n",
      "Run: 89 -> Derivative: 8.571137171173903e-05\n",
      "Run: 80 -> Derivative: 7.856620060346645e-05\n",
      "Run: 82 -> Derivative: 8.023921547077226e-05\n",
      "Run: 66 -> Derivative: 6.533143731753382e-05\n",
      "Run: 78 -> Derivative: 7.684265622138438e-05\n",
      "Run: 96 -> Derivative: 9.062580119713931e-05\n",
      "Run: 84 -> Derivative: 8.186161812360495e-05\n",
      "Run: 68 -> Derivative: 6.739314076004167e-05\n",
      "Run: 76 -> Derivative: 7.506651483210477e-05\n",
      "Run: 72 -> Derivative: 7.133708930288961e-05\n",
      "Run: 74 -> Derivative: 7.323752833653703e-05\n",
      "Run: 94 -> Derivative: 8.927729994027878e-05\n",
      "Run: 70 -> Derivative: 6.939447342384791e-05\n",
      "Run: 86 -> Derivative: 8.343597225256691e-05\n",
      "Run: 92 -> Derivative: 8.7882156054394e-05\n",
      "Run: 88 -> Derivative: 8.49649242479574e-05\n",
      "Run: 90 -> Derivative: 8.644500072250867e-05\n",
      "Run: 103 -> Derivative: 9.503328154083989e-05\n",
      "Run: 101 -> Derivative: 9.382826425801671e-05\n",
      "Run: 99 -> Derivative: 9.257949883555909e-05\n",
      "Run: 97 -> Derivative: 9.128781227043555e-05\n",
      "Run: 105 -> Derivative: 9.620025696311137e-05\n",
      "Run: 123 -> Derivative: 0.00010504647813592243\n",
      "Run: 107 -> Derivative: 9.733531030239819e-05\n",
      "Run: 125 -> Derivative: 0.00010585801026112617\n",
      "Run: 121 -> Derivative: 0.00010422659334133666\n",
      "Run: 109 -> Derivative: 9.8434720072342e-05\n",
      "Run: 111 -> Derivative: 9.949236649537581e-05\n",
      "Run: 119 -> Derivative: 0.0001033559309328841\n",
      "Run: 117 -> Derivative: 0.00010244400137570264\n",
      "Run: 115 -> Derivative: 0.00010149361645948521\n",
      "Run: 113 -> Derivative: 0.00010051081326210201\n",
      "Run: 127 -> Derivative: 0.0001065966012537069\n",
      "Run: 124 -> Derivative: 0.00010544939105898292\n",
      "Run: 126 -> Derivative: 0.00010623288798695401\n",
      "Run: 122 -> Derivative: 0.00010464166311983434\n",
      "Run: 102 -> Derivative: 9.443577623108782e-05\n",
      "Run: 104 -> Derivative: 9.561945699212331e-05\n",
      "Run: 100 -> Derivative: 9.320801653163048e-05\n",
      "Run: 120 -> Derivative: 0.00010379853971043331\n",
      "Run: 118 -> Derivative: 0.00010290488678625603\n",
      "Run: 108 -> Derivative: 9.788873667372842e-05\n",
      "Run: 128 -> Derivative: 0.00010696701319590476\n",
      "Run: 110 -> Derivative: 9.896738881976251e-05\n",
      "Run: 106 -> Derivative: 9.676939627684339e-05\n",
      "Run: 112 -> Derivative: 0.00010000651051070157\n",
      "Run: 116 -> Derivative: 0.00010197095910971206\n",
      "Run: 98 -> Derivative: 9.193832808586943e-05\n",
      "Run: 114 -> Derivative: 0.0001010068460438173\n",
      "CPU times: user 1min 25s, sys: 43.1 s, total: 2min 8s\n",
      "Wall time: 4h 35min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)\n",
    "\n",
    "start = 4\n",
    "finish = 5\n",
    "interval = 128\n",
    "\n",
    "a0_set = [(i,value) for i, value in enumerate(np.linspace(start, finish, interval))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.starmap(calculate_derivative_horseshoe_a0, a0_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "# Visualise the result\n",
    "\n",
    "result = np.block(derivatives)\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(result[:,0].min(), result[:,0].max(), 528) \n",
    "\n",
    "spl = make_interp_spline(result[:,0], result[:,1], k=3)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = \"horseshoe\"\n",
    "parameter = \"a0\"\n",
    "\n",
    "dump_to_disk = [derivatives, [xnew, power_smooth]]\n",
    "\n",
    "with open(f'../sensitivity/results_{M}_{prior}_{parameter}_{start}_{finish}_{interval}.pkl\"', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter -> $b_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative_horseshoe_b0(iteration, parameter_value):\n",
    "    \n",
    "    prior = \"horseshoe\"\n",
    "    T = 243\n",
    "    p = 1\n",
    "    train = T-25\n",
    "    iterations = 100\n",
    "    \n",
    "    error = np.sqrt(1.1e-16)\n",
    "    prior_parameters_plus = {\"a0\":4,\"b0\":parameter_value+error}\n",
    "    prior_parameters_minus = {\"a0\":4,\"b0\":parameter_value-error}\n",
    "    \n",
    "    msfe_plus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_plus)\n",
    "    msfe_minus, *_ = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=iterations, prior_parameters=prior_parameters_minus)\n",
    "    \n",
    "    derivative = (msfe_plus.mean() - msfe_minus.mean())/(2*error)\n",
    "    \n",
    "    print(f'Run: {iteration+1} -> Derivative: {derivative}')\n",
    "    \n",
    "    return [parameter_value, derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1 -> Derivative: 2.6655352790690587e-05\n",
      "Run: 25 -> Derivative: 4.4712004601246665e-05\n",
      "Run: 29 -> Derivative: 4.794076616572285e-05\n",
      "Run: 13 -> Derivative: 3.538844077820878e-05\n",
      "Run: 19 -> Derivative: 3.9975214064683415e-05\n",
      "Run: 5 -> Derivative: 2.95128754160004e-05\n",
      "Run: 7 -> Derivative: 3.0963097299988265e-05\n",
      "Run: 15 -> Derivative: 3.690101823362268e-05\n",
      "Run: 31 -> Derivative: 4.95855804364023e-05\n",
      "Run: 21 -> Derivative: 4.15369151400271e-05\n",
      "Run: 9 -> Derivative: 3.240951499792097e-05\n",
      "Run: 11 -> Derivative: 3.389099736731871e-05\n",
      "Run: 23 -> Derivative: 4.3115900452012754e-05\n",
      "Run: 27 -> Derivative: 4.63232427950044e-05\n",
      "Run: 17 -> Derivative: 3.843021832810373e-05\n",
      "Run: 3 -> Derivative: 2.8076216282296174e-05\n",
      "Run: 2 -> Derivative: 2.736441999149533e-05\n",
      "Run: 26 -> Derivative: 4.551543215615897e-05\n",
      "Run: 14 -> Derivative: 3.6142744713191295e-05\n",
      "Run: 6 -> Derivative: 3.02361669646636e-05\n",
      "Run: 30 -> Derivative: 4.876098175909601e-05\n",
      "Run: 16 -> Derivative: 3.7663344039199786e-05\n",
      "Run: 20 -> Derivative: 4.0754162509327673e-05\n",
      "Run: 22 -> Derivative: 4.2323802755569105e-05\n",
      "Run: 8 -> Derivative: 3.169424531985236e-05\n",
      "Run: 24 -> Derivative: 4.3911306136330465e-05\n",
      "Run: 32 -> Derivative: 5.039686446251549e-05\n",
      "Run: 12 -> Derivative: 3.4637610230494025e-05\n",
      "Run: 10 -> Derivative: 3.31482713898954e-05\n",
      "Run: 28 -> Derivative: 4.7135188418692414e-05\n",
      "Run: 18 -> Derivative: 3.920081410336599e-05\n",
      "Run: 4 -> Derivative: 2.8791568660061632e-05\n",
      "Run: 33 -> Derivative: 5.123022930768804e-05\n",
      "Run: 41 -> Derivative: 5.804972900975942e-05\n",
      "Run: 35 -> Derivative: 5.2909777451045115e-05\n",
      "Run: 39 -> Derivative: 5.631758385920479e-05\n",
      "Run: 47 -> Derivative: 6.335259897127117e-05\n",
      "Run: 45 -> Derivative: 6.156694711685363e-05\n",
      "Run: 43 -> Derivative: 5.979957189544027e-05\n",
      "Run: 37 -> Derivative: 5.460677523043785e-05\n",
      "Run: 53 -> Derivative: 6.881863543467094e-05\n",
      "Run: 49 -> Derivative: 6.51565274586929e-05\n",
      "Run: 51 -> Derivative: 6.697898067820937e-05\n",
      "Run: 55 -> Derivative: 7.067830351777057e-05\n",
      "Run: 59 -> Derivative: 7.44534619793446e-05\n",
      "Run: 57 -> Derivative: 7.255616553417754e-05\n",
      "Run: 61 -> Derivative: 7.637391433963009e-05\n",
      "Run: 63 -> Derivative: 7.830925264534885e-05\n",
      "Run: 34 -> Derivative: 5.206756373830945e-05\n",
      "Run: 42 -> Derivative: 5.892262431002698e-05\n",
      "Run: 36 -> Derivative: 5.375604344892649e-05\n",
      "Run: 40 -> Derivative: 5.718163029190924e-05\n",
      "Run: 48 -> Derivative: 6.425228897331862e-05\n",
      "Run: 54 -> Derivative: 6.974586443576993e-05\n",
      "Run: 44 -> Derivative: 6.068106796418038e-05\n",
      "Run: 46 -> Derivative: 6.245745745255056e-05\n",
      "Run: 38 -> Derivative: 5.546189009588234e-05\n",
      "Run: 52 -> Derivative: 6.789620301598933e-05\n",
      "Run: 60 -> Derivative: 7.541128986827866e-05\n",
      "Run: 58 -> Derivative: 7.350233276585552e-05\n",
      "Run: 56 -> Derivative: 7.16148775846138e-05\n",
      "Run: 50 -> Derivative: 6.606531442739402e-05\n",
      "Run: 62 -> Derivative: 7.733910250158392e-05\n",
      "Run: 64 -> Derivative: 7.92839512724406e-05\n",
      "Run: 65 -> Derivative: 8.0263859980434e-05\n",
      "Run: 67 -> Derivative: 8.22371574470076e-05\n",
      "Run: 69 -> Derivative: 8.423079903900666e-05\n",
      "Run: 71 -> Derivative: 8.624404045915954e-05\n",
      "Run: 73 -> Derivative: 8.827985889655287e-05\n",
      "Run: 81 -> Derivative: 9.661904822796736e-05\n",
      "Run: 77 -> Derivative: 9.24084758624702e-05\n",
      "Run: 79 -> Derivative: 9.450491317765567e-05\n",
      "Run: 75 -> Derivative: 9.033527716209999e-05\n",
      "Run: 83 -> Derivative: 9.875369280309824e-05\n",
      "Run: 85 -> Derivative: 0.0001009159590769775\n",
      "Run: 87 -> Derivative: 0.00010309286319719948\n",
      "Run: 91 -> Derivative: 0.00010750786921331356\n",
      "Run: 89 -> Derivative: 0.00010529019414254379\n",
      "Run: 93 -> Derivative: 0.00010974721160465842\n",
      "Run: 95 -> Derivative: 0.00011200747701930672\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)\n",
    "\n",
    "start = 1\n",
    "finish = 1.25\n",
    "interval = 128\n",
    "\n",
    "b0_set = [(i,value) for i, value in enumerate(np.linspace(start, finish, interval))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    derivatives = pool.starmap(calculate_derivative_horseshoe_b0, b0_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "# Visualise the result\n",
    "\n",
    "result = np.block(derivatives)\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(result[:,0].min(), result[:,0].max(), 528) \n",
    "\n",
    "spl = make_interp_spline(result[:,0], result[:,1], k=3)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = \"horseshoe\"\n",
    "parameter = \"b0\"\n",
    "\n",
    "dump_to_disk = [derivatives, [xnew, power_smooth]]\n",
    "\n",
    "with open(f'../sensitivity/results_{M}_{prior}_{parameter}_{start}_{finish}_{interval}.pkl\"', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
