{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy import io\n",
    "import pickle\n",
    "\n",
    "# Own code\n",
    "sys.path.append(\"../\")\n",
    "from utils.data_utils import generate_dgp_tvp_var, generate_matrices, generate_contemp_matrices\n",
    "from utils.tvp_models import TVPVARModel, tvp_ar_contemp, tvp_ar_non_contemp\n",
    "\n",
    "# Suppress scientific notation in numpy\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 175\n",
    "    prior_train = train-10\n",
    "    sparsity = 0.40\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=100)\n",
    "    msd_contemp = np.mean((mt1t_coeff_contemp - coefficients[:,1:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../simulations/datasets/y_2_200_1_0.4_8_het_py.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"<ipython-input-9-3ee1db285433>\", line 12, in simulation_run\n    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n  File \"/usr/local/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 981, in loadtxt\n    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n  File \"/usr/local/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 269, in open\n    return ds.open(path, mode, encoding=encoding, newline=newline)\n  File \"/usr/local/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 623, in open\n    raise IOError(\"%s not found.\" % path)\nOSError: ../simulations/datasets/y_2_200_1_0.4_8_het_py.csv not found.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         '''\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../simulations/datasets/y_2_200_1_0.4_8_het_py.csv not found."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "n_iterations = 200\n",
    "\n",
    "iterations_set = np.arange(1,n_iterations+1,1)\n",
    "M = (2,5)\n",
    "prior_list = [\"svss\"]#, \"lasso_alternative\", \"horseshoe\"]\n",
    "args_tuples = [x for sub_list in [x for sub_list in [[[(n, m, prior) for n in iterations_set] for m in M] for prior in prior_list] for x in sub_list] for x in sub_list]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    simulation_results = pool.starmap(simulation_run, args_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "train = 175\n",
    "p = 1\n",
    "sparsity = 0.40\n",
    "prior = \"svss\"\n",
    "\n",
    "simulation_parameters = [T,p,train, 1/2, 1/4, 4*1e-5, 1, 1/2, 1e-1*2, 1e-2, 1e-9, 12345]\n",
    "\n",
    "dump_to_disk = [simulation_results, simulation_parameters]\n",
    "\n",
    "with open(f'../simulations/results/statistics_{T}_{p}_{n_iterations}_{prior}_{sparsity}.pkl', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_set = []\n",
    "\n",
    "for run in range(1,11):\n",
    "\n",
    "    # Fixed for simulation\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 175\n",
    "    prior_train = train-10\n",
    "    sparsity = 0.05\n",
    "    M = 2\n",
    "    prior = \"lasso_alternative\"\n",
    "\n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "\n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "\n",
    "    prior_parameters = None\n",
    "\n",
    "    a0_set = np.linspace(1,5,5)\n",
    "    b0_set = np.hstack(([1], np.linspace(3,12,4)))\n",
    "    tpl_list = [x for sub_list in [[(a,b) for a in a0_set] for b in b0_set] for x in sub_list]\n",
    "\n",
    "    msfe_list = []\n",
    "\n",
    "    for parameters in tpl_list:\n",
    "\n",
    "        optim_pior_parameters = {'a0_lasso':parameters[0],'b0_lasso':parameters[1]}\n",
    "        msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "\n",
    "        msfe_list.append(msfe_contemp.mean())\n",
    "\n",
    "    optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "    prior_parameters = {'a0_lasso':optimal_prior[0],'b0_lasso':optimal_prior[1]}\n",
    "\n",
    "    print(f\"Run: {run} -> Optimal prior: {optimal_prior}\")\n",
    "    optimal_set.append(optimal_prior)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 175\n",
    "    prior_train = train-10\n",
    "    sparsity = 0.05\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "#     prior_parameters = None\n",
    "    \n",
    "#     if prior == 'lasso_alternative':\n",
    "        \n",
    "#         a0_set = np.linspace(1,5,5)\n",
    "#         b0_set = np.hstack(([1], np.linspace(3,12,4)))\n",
    "#         tpl_list = [x for sub_list in [[(a,b) for a in a0_set] for b in b0_set] for x in sub_list]\n",
    "        \n",
    "#         msfe_list = []\n",
    "        \n",
    "#         for parameters in tpl_list:\n",
    "            \n",
    "#             optim_pior_parameters = {'a0_lasso':parameters[0],'b0_lasso':parameters[1]}\n",
    "#             msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "            \n",
    "#             msfe_list.append(msfe_contemp.mean())\n",
    "        \n",
    "#         optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "#         prior_parameters = {'a0_lasso':optimal_prior[0],'b0_lasso':optimal_prior[1]}\n",
    "        \n",
    "#     elif prior == 'svss':\n",
    "        \n",
    "#         g0_set = np.linspace(1,5,5)\n",
    "#         h0_set = np.hstack(([1], np.linspace(3,12,4)))\n",
    "#         tpl_list = [x for sub_list in [[(g,h) for g in g0_set] for h in h0_set] for x in sub_list]\n",
    "        \n",
    "#         msfe_list = []\n",
    "        \n",
    "#         for parameters in tpl_list:\n",
    "            \n",
    "#             optim_pior_parameters = {'g0':parameters[0],'h0':parameters[1], 'pi0': 0.5}\n",
    "#             msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "            \n",
    "#             msfe_list.append(msfe_contemp.mean())\n",
    "        \n",
    "#         optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "#         prior_parameters = {'g0': optimal_prior[0], 'h0': optimal_prior[1], 'pi0': 0.5}\n",
    "        \n",
    "#     elif prior == 'horseshoe':\n",
    "#         prior_parameters = {'a0': 1, 'b0': 1}\n",
    "        \n",
    "#         a0_set = np.hstack(([1.5], np.linspace(3,12,4)))\n",
    "#         b0_set = np.hstack(([1.5],np.linspace(1,5,5)))\n",
    "#         tpl_list = [x for sub_list in [[(a,b) for a in a0_set] for b in b0_set] for x in sub_list]\n",
    "        \n",
    "#         msfe_list = []\n",
    "        \n",
    "#         for parameters in tpl_list:\n",
    "            \n",
    "#             optim_pior_parameters = {'a0':parameters[0],'b0':parameters[1]}\n",
    "#             msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "            \n",
    "#             msfe_list.append(msfe_contemp.mean())\n",
    "        \n",
    "#         optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "#         prior_parameters = {'a0':optimal_prior[0],'b0':optimal_prior[1]}\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=100)\n",
    "    msd_contemp = np.mean((mt1t_coeff_contemp - coefficients[:,1:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
