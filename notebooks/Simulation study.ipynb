{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation study\n",
    "\n",
    "This notebook contains all the code to conduct the simulation study for the VI-based TVP-BVARS. \n",
    "\n",
    "The three different priors are:\n",
    "\n",
    "- Stochastic Variable Search and Selection (SVSS)\n",
    "- Least Absolute Shrinkage and Selection Operator (Lasso)\n",
    "- Horseshoe\n",
    "\n",
    "A note of caution, this code runs completely parallel and uses all the available cores on the system that it is running on. Therefore, don't be afraid if your laptop starts to float (or freeze) this is normal. \n",
    "You can terminate the notebook in the terminal using Ctrl+C, this will close all the Python processes associated with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy import io\n",
    "import pickle\n",
    "\n",
    "# Own code\n",
    "sys.path.append(\"../\")\n",
    "from utils.data_utils import generate_dgp_tvp_var, generate_matrices, generate_contemp_matrices\n",
    "from utils.tvp_models import TVPVARModel, tvp_ar_contemp, tvp_ar_non_contemp, tvp_ar_contemp_decomposition\n",
    "\n",
    "# Suppress scientific notation in numpy\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only parameter that has to change for a different prior, is this global prior variable. All the 8 scenarios are calculated below.\n",
    "prior = 'lasso_alternative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation\n",
    "    T = 200\n",
    "    p = 1\n",
    "    sparsity = 0.40\n",
    "    \n",
    "    train = T - 25\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    model = tvp_ar_contemp_decomposition(T-p, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=25)\n",
    "    msfe_contemp, alpl_contemp, coeff_contemp, sigma_contemp, *_ = model.result()\n",
    "    \n",
    "    msd_contemp = np.mean((coefficients[:,:train].reshape(M,M, train) - coeff_contemp[:,1:,:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "n_iterations = 200\n",
    "\n",
    "iterations_set = np.arange(1,n_iterations+1,1)\n",
    "M = (3,7)\n",
    "prior_list = [prior]#, \"lasso_alternative\", \"horseshoe\"]\n",
    "args_tuples = [x for sub_list in [x for sub_list in [[[(n, m, prior) for n in iterations_set] for m in M] for prior in prior_list] for x in sub_list] for x in sub_list]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    simulation_results = pool.starmap(simulation_run, args_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "train = 175\n",
    "p = 1\n",
    "sparsity = 0.40\n",
    "\n",
    "simulation_parameters = [T,p,train, 1/3, 1/9, 4*1e-5, 1/6, 1/2, sparsity, 1e-2, 1e-9, 12345]\n",
    "\n",
    "dump_to_disk = [simulation_results, simulation_parameters]\n",
    "\n",
    "with open(f'../simulations/results/statistics_{T}_{p}_{n_iterations}_{prior}_{sparsity}_huber_2.pkl', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T = 200, SPARSITY = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation|\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = T - 25\n",
    "    sparsity = 0.20\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    model = tvp_ar_contemp_decomposition(T-p, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=25)\n",
    "    msfe_contemp, alpl_contemp, coeff_contemp, sigma_contemp = model.result()\n",
    "    \n",
    "    msd_contemp = np.mean((coefficients[:,:train].reshape(M,M, train) - coeff_contemp[:,1:,:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "n_iterations = 200\n",
    "\n",
    "iterations_set = np.arange(1,n_iterations+1,1)\n",
    "M = (3,7)\n",
    "prior_list = [prior]\n",
    "args_tuples = [x for sub_list in [x for sub_list in [[[(n, m, prior) for n in iterations_set] for m in M] for prior in prior_list] for x in sub_list] for x in sub_list]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    simulation_results = pool.starmap(simulation_run, args_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "train = 175\n",
    "p = 1\n",
    "sparsity = 0.20\n",
    "\n",
    "simulation_parameters = [T,p,train, 1/3, 1/9, 4*1e-5, 1/6, 1/2, sparsity, 1e-2, 1e-9, 12345]\n",
    "\n",
    "dump_to_disk = [simulation_results, simulation_parameters]\n",
    "\n",
    "with open(f'../simulations/results/statistics_{T}_{p}_{n_iterations}_{prior}_{sparsity}_huber.pkl', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T = 100, SPARSITY = 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation\n",
    "    T = 100\n",
    "    p = 1\n",
    "    train = 75\n",
    "    sparsity = 0.40\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    model = tvp_ar_contemp_decomposition(T-p, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=25)\n",
    "    msfe_contemp, alpl_contemp, coeff_contemp, sigma_contemp = model.result()\n",
    "    \n",
    "    msd_contemp = np.mean((coefficients[:,:train].reshape(M,M, train) - coeff_contemp[:,1:,:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "n_iterations = 200\n",
    "\n",
    "iterations_set = np.arange(1,n_iterations+1,1)\n",
    "M = (3,7)\n",
    "prior_list = [prior]#, \"lasso_alternative\", \"horseshoe\"]\n",
    "args_tuples = [x for sub_list in [x for sub_list in [[[(n, m, prior) for n in iterations_set] for m in M] for prior in prior_list] for x in sub_list] for x in sub_list]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    simulation_results = pool.starmap(simulation_run, args_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "train = 75\n",
    "p = 1\n",
    "sparsity = 0.40\n",
    "\n",
    "simulation_parameters = [T,p,train, 1/3, 1/9, 4*1e-5, 1/6, 1/2, sparsity, 1e-2, 1e-9, 12345]\n",
    "\n",
    "dump_to_disk = [simulation_results, simulation_parameters]\n",
    "\n",
    "with open(f'../simulations/results/statistics_{T}_{p}_{n_iterations}_{prior}_{sparsity}_huber.pkl', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T = 100, SPARSITY = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation\n",
    "    T = 100\n",
    "    p = 1\n",
    "    train = 75\n",
    "    sparsity = 0.20\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    model = tvp_ar_contemp_decomposition(T-p, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=25)\n",
    "    msfe_contemp, alpl_contemp, coeff_contemp, sigma_contemp = model.result()\n",
    "    \n",
    "    msd_contemp = np.mean((coefficients[:,:train].reshape(M,M, train) - coeff_contemp[:,1:,:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "# They are going to be some disgusting warnings for the first iterations of the model (has to do with initialization)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(12345)\n",
    "n_iterations = 200\n",
    "\n",
    "iterations_set = np.arange(1,n_iterations+1,1)\n",
    "M = (3,7)\n",
    "prior_list = [prior]#, \"lasso_alternative\", \"horseshoe\"]\n",
    "args_tuples = [x for sub_list in [x for sub_list in [[[(n, m, prior) for n in iterations_set] for m in M] for prior in prior_list] for x in sub_list] for x in sub_list]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    simulation_results = pool.starmap(simulation_run, args_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "train = 75\n",
    "p = 1\n",
    "sparsity = 0.20\n",
    "\n",
    "simulation_parameters = [T,p,train, 1/3, 1/9, 4*1e-5, 1/6, 1/2, sparsity, 1e-2, 1e-9, 12345]\n",
    "\n",
    "dump_to_disk = [simulation_results, simulation_parameters]\n",
    "\n",
    "with open(f'../simulations/results/statistics_{T}_{p}_{n_iterations}_{prior}_{sparsity}_huber.pkl', 'wb') as f:\n",
    "        pickle.dump(dump_to_disk, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "optimal_set = []\n",
    "\n",
    "for run in range(1,11):\n",
    "\n",
    "    # Fixed for simulation\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 175\n",
    "    prior_train = train-10\n",
    "    sparsity = 0.05\n",
    "    M = 2\n",
    "    prior = \"lasso_alternative\"\n",
    "\n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "\n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "\n",
    "    prior_parameters = None\n",
    "\n",
    "    a0_set = np.linspace(1,5,5)\n",
    "    b0_set = np.hstack(([1], np.linspace(3,12,4)))\n",
    "    tpl_list = [x for sub_list in [[(a,b) for a in a0_set] for b in b0_set] for x in sub_list]\n",
    "\n",
    "    msfe_list = []\n",
    "\n",
    "    for parameters in tpl_list:\n",
    "\n",
    "        optim_pior_parameters = {'a0_lasso':parameters[0],'b0_lasso':parameters[1]}\n",
    "        msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "\n",
    "        msfe_list.append(msfe_contemp.mean())\n",
    "\n",
    "    optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "    prior_parameters = {'a0_lasso':optimal_prior[0],'b0_lasso':optimal_prior[1]}\n",
    "\n",
    "    print(f\"Run: {run} -> Optimal prior: {optimal_prior}\")\n",
    "    optimal_set.append(optimal_prior)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def simulation_run(run, M, prior):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fixed for simulation\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 175\n",
    "    prior_train = train-10\n",
    "    sparsity = 0.05\n",
    "    \n",
    "    y = np.loadtxt(f'../simulations/datasets/y_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    coefficients = np.loadtxt(f'../simulations/datasets/coefficients_{M}_{T}_{p}_{sparsity}_{run}_het_py.csv', delimiter=\",\")\n",
    "    \n",
    "    y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "    \n",
    "#     prior_parameters = None\n",
    "    \n",
    "#     if prior == 'lasso_alternative':\n",
    "        \n",
    "#         a0_set = np.linspace(1,5,5)\n",
    "#         b0_set = np.hstack(([1], np.linspace(3,12,4)))\n",
    "#         tpl_list = [x for sub_list in [[(a,b) for a in a0_set] for b in b0_set] for x in sub_list]\n",
    "        \n",
    "#         msfe_list = []\n",
    "        \n",
    "#         for parameters in tpl_list:\n",
    "            \n",
    "#             optim_pior_parameters = {'a0_lasso':parameters[0],'b0_lasso':parameters[1]}\n",
    "#             msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "            \n",
    "#             msfe_list.append(msfe_contemp.mean())\n",
    "        \n",
    "#         optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "#         prior_parameters = {'a0_lasso':optimal_prior[0],'b0_lasso':optimal_prior[1]}\n",
    "        \n",
    "#     elif prior == 'svss':\n",
    "        \n",
    "#         g0_set = np.linspace(1,5,5)\n",
    "#         h0_set = np.hstack(([1], np.linspace(3,12,4)))\n",
    "#         tpl_list = [x for sub_list in [[(g,h) for g in g0_set] for h in h0_set] for x in sub_list]\n",
    "        \n",
    "#         msfe_list = []\n",
    "        \n",
    "#         for parameters in tpl_list:\n",
    "            \n",
    "#             optim_pior_parameters = {'g0':parameters[0],'h0':parameters[1], 'pi0': 0.5}\n",
    "#             msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "            \n",
    "#             msfe_list.append(msfe_contemp.mean())\n",
    "        \n",
    "#         optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "#         prior_parameters = {'g0': optimal_prior[0], 'h0': optimal_prior[1], 'pi0': 0.5}\n",
    "        \n",
    "#     elif prior == 'horseshoe':\n",
    "#         prior_parameters = {'a0': 1, 'b0': 1}\n",
    "        \n",
    "#         a0_set = np.hstack(([1.5], np.linspace(3,12,4)))\n",
    "#         b0_set = np.hstack(([1.5],np.linspace(1,5,5)))\n",
    "#         tpl_list = [x for sub_list in [[(a,b) for a in a0_set] for b in b0_set] for x in sub_list]\n",
    "        \n",
    "#         msfe_list = []\n",
    "        \n",
    "#         for parameters in tpl_list:\n",
    "            \n",
    "#             optim_pior_parameters = {'a0':parameters[0],'b0':parameters[1]}\n",
    "#             msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(train, M, p, prior_train, X_matrix_contemp[:train], y_matrix_contemp[:,:train], prior, print_status=False, iterations=100, prior_parameters=optim_pior_parameters)\n",
    "            \n",
    "#             msfe_list.append(msfe_contemp.mean())\n",
    "        \n",
    "#         optimal_prior = tpl_list[msfe_list.index(min(msfe_list))]\n",
    "#         prior_parameters = {'a0':optimal_prior[0],'b0':optimal_prior[1]}\n",
    "    \n",
    "    # Contemperanous values added \n",
    "    msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp, ar_model = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp, prior, print_status=False, iterations=100)\n",
    "    msd_contemp = np.mean((mt1t_coeff_contemp - coefficients[:,1:train])**2)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Run: {run}, M: {M} & prior: {prior} -> MSD: {msd_contemp} | MSFE: {msfe_contemp.mean()} | ALPL: {alpl_contemp.mean()}')\n",
    "    \n",
    "    return [msfe_contemp, alpl_contemp, msd_contemp, M, prior]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
