{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy import io\n",
    "\n",
    "# Own code\n",
    "sys.path.append(\"../\")\n",
    "from utils.data_utils import create_data, create_dgp_data, transformation, standardize, generate_dgp_tvp_var, generate_matrices, generate_contemp_matrices\n",
    "from utils.tvp_models import TVPVARModel, tvp_ar_contemp, tvp_ar_non_contemp\n",
    "\n",
    "# Suppress scientific notation in numpy\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data according to a TVP-VAR DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2\n",
    "T = 200\n",
    "p = 1\n",
    "train = 150\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def generate_dgp_tvp_var(M, T, p, diagonal_coefficient, cross_coefficient, sigma_states, sigma_observation, covariance, binomial_prob):\n",
    "\n",
    "#     y = np.zeros((M,T))\n",
    "#     A_1_vec = np.zeros((M*(M*p),T))\n",
    "#     selection_mask = np.random.binomial(1,binomial_prob,M*(M*p)) == 1\n",
    "    \n",
    "#     for t in range(T):\n",
    "\n",
    "#         if t == 0:\n",
    "#             A_1_vec[selection_mask,t] = cross_coefficient\n",
    "#             np.fill_diagonal(A_1_vec[:,t].reshape(M,(M*p)), np.repeat(diagonal_coefficient,M)) \n",
    "#             y[:,t] = np.ones(M)\n",
    "#         else:\n",
    "#             A_1_vec[:,t] = A_1_vec[:,t-1] + multivariate_normal.rvs(mean=np.zeros(M**2), cov=np.diag(np.ones(M**2)*sigma_states))\n",
    "\n",
    "#             ## Eigen values check\n",
    "#             eigen_values = np.linalg.eig(A_1_vec[:,t].reshape(M,M))[0]\n",
    "#             stationary = any(eigen_values < 1)\n",
    "#             if stationary == False:\n",
    "#                 print(f'Failed eigen values requirement < 1 (explosive process)')\n",
    "#                 print(f'Iteration: {t}')\n",
    "#                 break\n",
    "\n",
    "#             Z = np.zeros((M,M**2))\n",
    "#             for m in range(M):\n",
    "#                 Z[m,m*M:(m*M+M)] = y[:,t-1]\n",
    "#             y[:,t] = Z@A_1_vec[:,t] + multivariate_normal.rvs(mean=np.zeros(M), cov=(np.diag(np.ones(M))*sigma_observation + np.tril(np.repeat(covariance,M),-1)))\n",
    "            \n",
    "#     return y, A_1_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, coefficients = generate_dgp_tvp_var(M, T, p, 1/2, 1/4, 4*1e-5, 1, 1/2, 1e-2)\n",
    "y_matrix, X_matrix = generate_matrices(T, M, p, y)\n",
    "y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../data/y.csv\",y[:,1:].T, delimiter=\",\")\n",
    "np.savetxt(\"../data/x.csv\",x.T, delimiter=\",\")\n",
    "np.savetxt(\"../data/coeff.csv\", A_1_vec[:M,1:], delimiter=\",\")\n",
    "np.savetxt(\"../data/sigma_obs.csv\", sigma_observations[:,1:], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the matrices for the own implementation of TVP-(V)AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def generate_matrices(T, M, p, y):\n",
    "\n",
    "#     series = y\n",
    "\n",
    "#     lagged_T = T - p\n",
    "#     lagged_series = []\n",
    "#     y_series = []\n",
    "\n",
    "#     lagged_y = np.ones((lagged_T, M * p))\n",
    "#     k = M*(M*p)\n",
    "#     position_counter = 0\n",
    "#     total_lags = M * p\n",
    "\n",
    "#     for m in range(M):\n",
    "#         y_m = series[m]\n",
    "#         for i in range(1, p + 1):\n",
    "\n",
    "#             lagged_y[:, position_counter] = y_m[(p - i):-i]\n",
    "#             position_counter += 1\n",
    "\n",
    "#     # Create lagged dependent matrix\n",
    "#     X = np.zeros((lagged_T, M, k))\n",
    "#     stacked_X = np.zeros((M, lagged_T, k))\n",
    "\n",
    "#     for m in range(M):\n",
    "#         stacked_X[m, :, m * (total_lags):(m + 1) * total_lags] = lagged_y\n",
    "\n",
    "#     stacked_list = list()\n",
    "\n",
    "#     for m in range(M):\n",
    "#         stacked_list.append(stacked_X[m])\n",
    "\n",
    "#     for t in range(lagged_T):\n",
    "#         X[t] = np.squeeze(np.dstack(tuple(stacked_list)))[t].T\n",
    "\n",
    "#     for s in series:\n",
    "#         y_series.append(s[p:])\n",
    "\n",
    "#     y_own = np.array(y_series)\n",
    "#     X_own = X\n",
    "\n",
    "#     return y_own, X_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def generate_contemp_matrices(T, M, p, y):\n",
    "\n",
    "#     # Contemperous values added\n",
    "\n",
    "#     series = y\n",
    "\n",
    "#     lagged_T = T - p\n",
    "#     lagged_series = []\n",
    "#     y_series = []\n",
    "\n",
    "#     lagged_y = np.ones((lagged_T, M * p))\n",
    "#     k = M*(M*p)+M*(M-1)\n",
    "#     variable_list = np.arange(M)\n",
    "#     position_counter = 0\n",
    "#     total_lags = M * p + (M-1)\n",
    "\n",
    "#     for m in range(M):\n",
    "#         y_m = series[m]\n",
    "#         for i in range(1, p + 1):\n",
    "\n",
    "#             lagged_y[:, position_counter] = y_m[(p - i):-i]\n",
    "#             position_counter += 1\n",
    "\n",
    "#     # Create lagged dependent matrix\n",
    "#     X = np.zeros((lagged_T, M, k))\n",
    "#     stacked_X = np.zeros((M, lagged_T, k))\n",
    "\n",
    "#     for m in range(M):\n",
    "#         contemp_y = np.zeros((T-1,M-1))\n",
    "\n",
    "#         if m != 0:\n",
    "#             contemp_y[:,:m] = series[:m][:,1:].T\n",
    "\n",
    "#         stacked_X[m, :, m * (total_lags):(m + 1) * total_lags] = np.hstack((lagged_y, contemp_y))\n",
    "\n",
    "#     stacked_list = list()\n",
    "\n",
    "#     for m in range(M):\n",
    "#         stacked_list.append(stacked_X[m])\n",
    "\n",
    "#     for t in range(lagged_T):\n",
    "#         X[t] = np.squeeze(np.dstack(tuple(stacked_list)))[t].T\n",
    "\n",
    "#     for s in series:\n",
    "#         y_series.append(s[p:])\n",
    "\n",
    "#     y_own = np.array(y_series)\n",
    "#     X_own = X\n",
    "    \n",
    "#     return y_own, X_own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# y_0 = 5\n",
    "# y_series = np.zeros(T+1)\n",
    "# phi = 0.5\n",
    "# sigma = 0.5\n",
    "# location = 0\n",
    "\n",
    "# for i in range(T+1):\n",
    "\n",
    "#     if i == 0:\n",
    "        \n",
    "#         y_series[i] = phi*y_0 + np.random.normal(location, sigma)\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         y_series[i] = phi*y_series[i-1] + np.random.normal(location, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #y_series = (y_series - y_series.mean())/y_series.std()\n",
    "\n",
    "# x = y_series[:-1]\n",
    "# y = y_series[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# tvp_ar = TVPVARModel(np.expand_dims(x,1),np.expand_dims(y,1), p, train, False, homoskedastic=True)\n",
    "# tvp_ar.k = 1\n",
    "# tvp_ar.iterations = 25\n",
    "# tvp_ar.initialize_priors(prior='horseshoe')#,prior_parameters={'b0': 2, 'a0': 2})\n",
    "# mt1t, st1t  = tvp_ar.train(print_status=True)\n",
    "# #mt1t_mean_set.append(mt1t)\n",
    "# #sigma_set.append(tvp_ar.sigma_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGP according to Koop & Korobilis (2020) - MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_matlab_dict = io.loadmat('../../Gary Koop & Dimitris Korobilis (2020) - VBDVS/MONTE_CARLO/y.mat')\n",
    "x_matlab_dict = io.loadmat('../../Gary Koop & Dimitris Korobilis (2020) - VBDVS/MONTE_CARLO/x.mat')\n",
    "\n",
    "y_matlab = y_matlab_dict['y']\n",
    "x_matlab = x_matlab_dict['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVP-AR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default implementation from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>AutoReg Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>    <td>199</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>           <td>AutoReg-X(0)</td>   <th>  Log Likelihood     </th> <td>-320.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>Conditional MLE</td> <th>  S.D. of innovations</th>   <td>1.211</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 21 Sep 2020</td> <th>  AIC                </th>   <td>0.413</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:54:41</td>     <th>  BIC                </th>   <td>0.462</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                <td>0</td>        <th>  HQIC               </th>   <td>0.433</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                      <td>199</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>    0.1102</td> <td>    0.087</td> <td>    1.263</td> <td> 0.207</td> <td>   -0.061</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    0.5383</td> <td>    0.060</td> <td>    8.996</td> <td> 0.000</td> <td>    0.421</td> <td>    0.656</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            AutoReg Model Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  199\n",
       "Model:                   AutoReg-X(0)   Log Likelihood                -320.430\n",
       "Method:               Conditional MLE   S.D. of innovations              1.211\n",
       "Date:                Mon, 21 Sep 2020   AIC                              0.413\n",
       "Time:                        16:54:41   BIC                              0.462\n",
       "Sample:                             0   HQIC                             0.433\n",
       "                                  199                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept      0.1102      0.087      1.263      0.207      -0.061       0.281\n",
       "x1             0.5383      0.060      8.996      0.000       0.421       0.656\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR, AutoReg as AR\n",
    "\n",
    "x = y[0,:-1]\n",
    "\n",
    "ar_ols = AR(y.T[1:,0], exog=x.T, lags=0)\n",
    "results_ar = ar_ols.fit()\n",
    "results_ar.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvp_ar_contemp(T, M, p, train, X, y, total_h=8, iterations=50, print_status=False):\n",
    "\n",
    "    # Contemperous values added\n",
    "\n",
    "    mt1t_mean_set = []\n",
    "    sigma_set = []\n",
    "    msfe_set = []\n",
    "    alpl_set = []\n",
    "\n",
    "    for m in range(M):\n",
    "\n",
    "        tvp_ar = TVPVARModel(np.expand_dims(X[:,m,(m*(M+M-1)):(m*(M+M-1)+(M+M-1))],1),\n",
    "                             np.expand_dims(y[m,:].T,1), p, train, False, homoskedastic=False)\n",
    "        tvp_ar.k = M+M-1\n",
    "        tvp_ar.iterations = iterations\n",
    "        tvp_ar.initialize_priors(prior='lasso')\n",
    "        mt1t, st1t  = tvp_ar.train(print_status=print_status)\n",
    "        mt1t_mean_set.append(mt1t)\n",
    "        sigma_set.append(tvp_ar.sigma_t)\n",
    "\n",
    "        msfe, alpl = tvp_ar.calculate_metrics(total_h, constant=False, print_status=print_status)\n",
    "\n",
    "        msfe_set.append(msfe)\n",
    "        alpl_set.append(alpl)\n",
    "\n",
    "#         print(f'Variable: {m+1} | MSFE: {msfe.mean()}')\n",
    "        \n",
    "    msfe = np.block(msfe_set).mean(1)\n",
    "    alpl = np.block(alpl_set).reshape(total_h,M).mean(1)\n",
    "    mt1t_full = np.vstack(mt1t_mean_set)\n",
    "    mt1t_coeff = mt1t_full.reshape((M,M+M-1,train-1))[:,:M,:].reshape(M**2,train-1)\n",
    "    sigma = np.block(sigma_set)\n",
    "    \n",
    "    return msfe, alpl, mt1t_full, mt1t_coeff, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvp_ar_non_contemp(T, M, p, train, X, y, total_h=8, iterations=50, print_status=False):\n",
    "\n",
    "    mt1t_mean_set = []\n",
    "    sigma_set = []\n",
    "    msfe_set = []\n",
    "    alpl_set = []\n",
    "\n",
    "    for m in range(M):\n",
    "\n",
    "        tvp_ar = TVPVARModel(np.expand_dims(X[:,0,0:M],1),\n",
    "                             np.expand_dims(y[m,:].T,1), p, train, False, homoskedastic=False)\n",
    "        tvp_ar.k = M\n",
    "        tvp_ar.iterations = iterations\n",
    "        tvp_ar.initialize_priors(prior='lasso')#,prior_parameters={'g0': 1, 'h0': 12, 'pi0': 0.5})\n",
    "        mt1t, st1t  = tvp_ar.train(print_status=print_status)\n",
    "        mt1t_mean_set.append(mt1t)\n",
    "        sigma_set.append(tvp_ar.sigma_t)\n",
    "\n",
    "        msfe, alpl = tvp_ar.calculate_metrics(total_h, constant=False, print_status=print_status)\n",
    "\n",
    "        msfe_set.append(msfe)\n",
    "        alpl_set.append(alpl)\n",
    "\n",
    "#         print(f'Variable: {m+1} | MSFE: {msfe.mean()}')\n",
    "        \n",
    "    msfe = np.block(msfe_set).mean(1)\n",
    "    alpl = np.block(alpl_set).reshape(total_h,M).mean(1)\n",
    "    mt1t = np.vstack(mt1t_mean_set)\n",
    "    sigma = np.block(sigma_set)\n",
    "\n",
    "    return msfe, alpl, mt1t, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32293792, 0.25452129, 0.22797044, 0.18725939, 0.2564775 ,\n",
       "       0.00215432, 0.        , 0.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.block(alpl_set).reshape(8,M).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: 1 | MSFE: 1.918595483630126\n",
      "Variable: 2 | MSFE: 2.2909982865807557\n",
      "Variable: 3 | MSFE: 1.9892186789081046\n",
      "Variable: 4 | MSFE: 1.6293542014052078\n",
      "Variable: 5 | MSFE: 2.3291591005586536\n",
      "Variable: 6 | MSFE: 1.5767875400800528\n",
      "Variable: 7 | MSFE: 2.180804467415127\n",
      "Variable: 8 | MSFE: 1.469357843639956\n",
      "Variable: 9 | MSFE: 1.406332702555365\n",
      "Variable: 10 | MSFE: 1.7970092354121434\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'A_1_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f5c9e922f865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmsfe_contemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt1t_full_contemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt1t_coeff_contemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_contemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvp_ar_contemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_matrix_contemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_matrix_contemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mMSD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt1t_coeff_contemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA_1_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' MSD (contemp): {round(MSD,6)} \\n MSFE: {np.round(msfe_contemp,6)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A_1_vec' is not defined"
     ]
    }
   ],
   "source": [
    "#Contemperanous values added\n",
    "\n",
    "msfe_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp)\n",
    "\n",
    "MSD = np.mean((mt1t_coeff_contemp - coefficients[:,1:train])**2)\n",
    "\n",
    "print(f' MSD (contemp): {round(MSD,6)} \\n MSFE: {np.round(msfe_contemp,6)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: 1 | MSFE: 1.918595483630126\n",
      "Variable: 2 | MSFE: 2.2818936548717597\n",
      "Variable: 3 | MSFE: 2.000534149153527\n",
      "Variable: 4 | MSFE: 1.664597352249343\n",
      "Variable: 5 | MSFE: 2.333814395284434\n",
      "Variable: 6 | MSFE: 1.615711536898325\n",
      "Variable: 7 | MSFE: 2.213052235904386\n",
      "Variable: 8 | MSFE: 1.4766771903928078\n",
      "Variable: 9 | MSFE: 1.4360085327902024\n",
      "Variable: 10 | MSFE: 1.7987455902325669\n",
      " MSD (non-contemp): 0.021856 \n",
      " MSFE: [1.23018  2.124239 1.960989 1.966036 1.937644 1.872929 1.881806 1.896271]\n"
     ]
    }
   ],
   "source": [
    "msfe, mt1t, sigma = tvp_ar_non_contemp(T, M, p, train, X_matrix, y_matrix)\n",
    "\n",
    "MSD = np.mean((mt1t - coefficients[:,1:train])**2)\n",
    "\n",
    "print(f' MSD (non-contemp): {round(MSD,6)} \\n MSFE: {np.round(msfe_contemp,6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of the DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 -> MSD: 0.029838997781348468 - 0.04348741417883704 | MSFE: 510119274.759257 - 2.424451858747738 | ALPL: 0.1388469008284308 - 0.2230257650865761\n",
      "Run 20 -> MSD: 0.050221740811985785 - 0.05073626552366491 | MSFE: 0.9683366773237679 - 0.9703132716000107 | ALPL: 0.3337260558705476 - 0.32742295978289393\n",
      "Run 30 -> MSD: 0.054969552857254314 - 0.05748491306342933 | MSFE: 1.6185593715536708 - 1.6170613082433773 | ALPL: 0.12843912528196655 - 0.1281471259882881\n",
      "Run 40 -> MSD: 0.03237452812890052 - 0.03259107743674183 | MSFE: 1.3071069278169287 - 1.3032075337868811 | ALPL: 0.2110755072151248 - 0.18732398119310312\n",
      "Run 50 -> MSD: 0.0353268117767048 - 0.03646458621498609 | MSFE: 2.030587545321864 - 2.036245628647201 | ALPL: 0.24367936922662375 - 0.23863146858094753\n",
      "Run 60 -> MSD: 0.05513962661933871 - 0.045096350888538334 | MSFE: 1.1381108394488013 - 1.1471089330230937 | ALPL: 0.349005190395894 - 0.28650764085698693\n",
      "Run 70 -> MSD: 0.1101510561259764 - 0.11229754985661082 | MSFE: 1.3103478430832025 - 1.3032094634143254 | ALPL: 0.3262378603307077 - 0.2824240520581017\n",
      "Run 80 -> MSD: 0.03749498542990585 - 0.035600431299860125 | MSFE: 1.4378700487526888 - 1.4468713322879605 | ALPL: 0.22496555048343134 - 0.23419666665908345\n",
      "Run 90 -> MSD: 0.06419441914747463 - 0.06773231462933728 | MSFE: 1.8192944603459822 - 1.8053763138135666 | ALPL: 0.17452897389293037 - 0.18703401103385323\n",
      "Run 100 -> MSD: 0.028559026768255773 - 0.03249510598632246 | MSFE: 1.1081701619021809 - 1.1099376740281568 | ALPL: 0.23965778992401654 - 0.24322690774041741\n",
      "Run 110 -> MSD: 0.057480732685253486 - 0.04880022838317572 | MSFE: 1.2333877305689032 - 1.2406834520063514 | ALPL: 0.22085121010962594 - 0.21937520615226286\n",
      "Run 120 -> MSD: 0.0514370394425652 - 0.04984179621858942 | MSFE: 1.229956346353382 - 1.2240984457283843 | ALPL: 0.37654561179388146 - 0.3612583266912848\n",
      "Run 130 -> MSD: 0.039821110076154666 - 0.036586587352188685 | MSFE: 1.1597825903751895 - 1.1603629244930205 | ALPL: 0.2502068722110707 - 0.254916639490681\n",
      "Run 140 -> MSD: 0.030409752952078158 - 0.028755993828810052 | MSFE: 1.2371093741202395 - 1.2333731006508577 | ALPL: 0.28286886681299983 - 0.27331531629085826\n",
      "Run 150 -> MSD: 0.03796341478987883 - 0.03791369999143844 | MSFE: 1.3604073898359283 - 1.3545314741904284 | ALPL: 0.24166810263491095 - 0.26785929141024306\n",
      "Run 160 -> MSD: 0.03701183021354165 - 0.03610108472149614 | MSFE: 2.550555656732252 - 2.583038299507659 | ALPL: 0.1660239318126599 - 0.13147981936395256\n",
      "Run 170 -> MSD: 0.048186544022491014 - 0.038134020509674335 | MSFE: 1.0231741482580068 - 1.0096054262200347 | ALPL: 0.2231094064459457 - 0.22514495691962794\n",
      "Run 180 -> MSD: 0.03170522427170466 - 0.03337213674203753 | MSFE: 1.2924589274364173 - 1.2831691229957864 | ALPL: 0.44107196487042644 - 0.3943207692056758\n",
      "Run 190 -> MSD: 0.03167706757257406 - 0.02984318388336217 | MSFE: 1.3620728053052398 - 1.358960353782103 | ALPL: 0.27442500865564456 - 0.2795491934570867\n",
      "Run 200 -> MSD: 0.04617745403688845 - 0.04123978912474266 | MSFE: 1.2616187293507255 - 1.2660202172974329 | ALPL: 0.18023976787589507 - 0.14783824807651316\n",
      "Run 10 -> MSD: 0.03144031594399917 - 0.026475037217106836 | MSFE: 2.0381821003849065 - 2.0357648224043263 | ALPL: 0.11845536441361262 - 0.07988034923018635\n",
      "Run 20 -> MSD: 0.025172490091292753 - 0.023893207259901565 | MSFE: 2.025585343204911 - 2.016695273992684 | ALPL: 0.184071433775143 - 0.166175153967537\n",
      "Run 30 -> MSD: 0.032242179202858906 - 0.02288318909754596 | MSFE: 1.2252154599090275 - 1.2188817832649688 | ALPL: 0.26901174379763354 - 0.29709590965111266\n",
      "Run 40 -> MSD: 0.028441246519409016 - 0.023737492033203304 | MSFE: 1.4814181821096644 - 1.4699174149631413 | ALPL: 0.16969916716246886 - 0.15274721163916608\n",
      "Run 50 -> MSD: 0.02981265223074294 - 0.024809034310439494 | MSFE: 1.3443792108304071 - 1.333768184803704 | ALPL: 0.39915258861900554 - 0.38170069164140463\n",
      "Run 60 -> MSD: 0.034729231552265635 - 0.026932996957766436 | MSFE: 1.399368150503775 - 1.3799878924282543 | ALPL: 0.31861440357635473 - 0.27139723918063147\n",
      "Run 70 -> MSD: 0.029282114506614262 - 0.02549201617887528 | MSFE: 1.6471176776672718 - 1.6085785475849952 | ALPL: 0.22855505815427468 - 0.14102424603618374\n",
      "Run 80 -> MSD: 0.03236428485078734 - 0.02375804570104578 | MSFE: 1.533867629509007 - 1.5315852630169342 | ALPL: 0.21045459789214377 - 1.0957697823906292\n",
      "Run 90 -> MSD: 0.03217626429187649 - 0.026631510524140856 | MSFE: 1.3872844828290394 - 1.377601064129201 | ALPL: 0.1467498779470685 - 0.1545144175827532\n",
      "Run 100 -> MSD: 0.035802708377074145 - 0.027815960302241156 | MSFE: 1.2871121260819416 - 1.2684527510787724 | ALPL: 0.2094296668507233 - 0.16930936311106703\n",
      "Run 110 -> MSD: 0.03209147077540055 - 0.02443563913515458 | MSFE: 1.4136300968024924 - 1.3997101135696077 | ALPL: 0.21997378480926927 - 0.22210955938330557\n",
      "Run 120 -> MSD: 0.031138156469143384 - 0.02597198633336564 | MSFE: 1.689907207403722 - 1.6716325117541482 | ALPL: 0.2959855302249421 - 0.31451854506906574\n",
      "Run 130 -> MSD: 0.025854810108041706 - 0.01960324752868354 | MSFE: 1.3873567805100597 - 1.3901927199237596 | ALPL: 0.47158790636686654 - 0.5977004466223018\n",
      "Run 140 -> MSD: 0.031123665714668704 - 0.02355440114229091 | MSFE: 1.9060489846516186 - 1.894178543048323 | ALPL: 0.12641330159912342 - 0.10493645551516084\n",
      "Run 150 -> MSD: 0.022053979472197095 - 0.018599117072767818 | MSFE: 1.616791045396088 - 1.6125816879980004 | ALPL: 0.47895303946297 - 0.36487451685046357\n",
      "Run 160 -> MSD: 0.03816225220195109 - 0.03317768688164131 | MSFE: 1.4324515313369317 - 1.4271131363708924 | ALPL: 0.1835466469571816 - 0.1730689259770081\n",
      "Run 170 -> MSD: 0.023200336680360967 - 0.01943571629151395 | MSFE: 1.6903010458495595 - 1.6958407671891056 | ALPL: 0.1672789055747682 - 0.16308949331951036\n",
      "Run 180 -> MSD: 0.038617446113383 - 0.026581021275071445 | MSFE: 1.417651983135369 - 1.406865182461865 | ALPL: 0.2103662049266144 - 0.17552070918490728\n",
      "Run 190 -> MSD: 0.02872315960135406 - 0.024449194322121285 | MSFE: 1.5816062751141582 - 1.56969819734875 | ALPL: 0.4237740343654537 - 0.4240575349055754\n",
      "Run 200 -> MSD: 0.027330284397367434 - 0.024739438099784208 | MSFE: 1.4335761308336457 - 1.431681196992517 | ALPL: 0.3639702313570089 - 0.3799970473332991\n",
      "Run 10 -> MSD: 0.019312582765091096 - 0.015117073619763858 | MSFE: 2.519187562276198 - 2.483394426458572 | ALPL: 0.14693847253666215 - 0.12336461701580313\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "different_m = [2,5,10]\n",
    "\n",
    "for M in different_m:\n",
    "\n",
    "    n_iterations = 200\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    # M = 10\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 150\n",
    "    prior = 'lasso'\n",
    "\n",
    "    contemperanous_statistics = []\n",
    "    non_contemperanous_statistics = []\n",
    "\n",
    "    for run in range(n_iterations):\n",
    "\n",
    "        y, coefficients = generate_dgp_tvp_var(M, T, p, 1/2, 1/4, 4*1e-5, 1, 1/2, 1e-2)\n",
    "        y_matrix, X_matrix = generate_matrices(T, M, p, y)\n",
    "        y_matrix_contemp, X_matrix_contemp = generate_contemp_matrices(T, M, p, y)\n",
    "\n",
    "        # Without contemperanous values\n",
    "        msfe, alpl, mt1t, sigma = tvp_ar_non_contemp(T, M, p, train, X_matrix, y_matrix)\n",
    "        msd = np.mean((mt1t - coefficients[:,1:train])**2)\n",
    "\n",
    "        non_contemperanous_statistics.append([msfe, alpl, msd])\n",
    "\n",
    "        # Contemperanous values added \n",
    "        msfe_contemp, alpl_contemp, mt1t_full_contemp, mt1t_coeff_contemp, sigma_contemp = tvp_ar_contemp(T, M, p, train, X_matrix_contemp, y_matrix_contemp)\n",
    "        msd_contemp = np.mean((mt1t_coeff_contemp - coefficients[:,1:train])**2)    \n",
    "\n",
    "        contemperanous_statistics.append([msfe_contemp, alpl_contemp, msd_contemp])\n",
    "\n",
    "        if ((run+1) % (n_iterations/20) == 0.0):\n",
    "            print(f'Run {run+1} -> MSD: {msd} - {msd_contemp} | MSFE: {msfe.mean()} - {msfe_contemp.mean()} | ALPL: {alpl.mean()} - {alpl_contemp.mean()}')\n",
    "\n",
    "    # Save simulation parameters\n",
    "    simulation_parameters = [M,T,p,train, 1/2, 1/4, 4*1e-5, 1, 1/2, 1e-2, 12345, prior]\n",
    "\n",
    "    simulation_statistics = [contemperanous_statistics, non_contemperanous_statistics, simulation_parameters]\n",
    "\n",
    "    with open(f'../simulations/statistics_{M}_{T}_{p}_{prior}_{n_iterations}.pkl', 'wb') as f:\n",
    "        pickle.dump(simulation_statistics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_m = [2,5,10]\n",
    "\n",
    "for M in different_m:\n",
    "\n",
    "    n_iterations = 200\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    # M = 10\n",
    "    T = 200\n",
    "    p = 1\n",
    "    train = 150\n",
    "    prior = 'lasso'\n",
    "\n",
    "    contemperanous_statistics = []\n",
    "    non_contemperanous_statistics = []\n",
    "\n",
    "    for run in range(n_iterations):\n",
    "\n",
    "        y, coefficients = generate_dgp_tvp_var(M, T, p, 1/2, 1/4, 4*1e-5, 1, 1/2, 1e-2)\n",
    "    \n",
    "    x = y[:,:-1]\n",
    "    np.savetxt(f'../simulations/datasets/y_{M}_{T}_{p}_{prior}_{run}.csv',y[:,1:].T, delimiter=\",\")\n",
    "    np.savetxt(f'../simulations/datasets/x_{M}_{T}_{p}_{prior}_{run}.csv',x.T, delimiter=\",\")\n",
    "    np.savetxt(f'../simuations/datasets/coefficients_{M}_{T}_{p}_{prior}_{run}.csv', coefficients[:,1:], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_h = 8\n",
    "\n",
    "msfe_rw = np.zeros(total_h)\n",
    "\n",
    "for h in range(total_h):\n",
    "\n",
    "    msfe_rw[h] = np.mean((y_own[:,(train-1+h):] - y_own[:,(train-2):-(h+1)])**2,1)[0]\n",
    "    ratio = msfe_ar[h]/msfe_rw[h]\n",
    "    \n",
    "    print(f'Ratio VAR_IE_VI/RW ({h+1}-step ahead): {np.round(ratio,4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((np.vstack(mt1t_mean_set)[:,:] - A_1_vec[:,1:train])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'VAR_IE_VI: {full_mt1t.mean(1)}')\n",
    "print(f'TRUE: {A_1_vec[:,1:train].mean(1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(full_mt1t[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvp_ar = TVPVARModel(np.expand_dims(x_matlab,1),y_matlab, p, 300, False, homoskedastic=False)\n",
    "# tvp_ar.k = 10\n",
    "# tvp_ar.iterations = 1000\n",
    "# tvp_ar.initialize_priors(prior='svss',prior_parameters={'g0': 1, 'h0': 12, 'pi0': 0.5})\n",
    "# mt1t, st1t = tvp_ar.train(threshold=1e-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSD = ((mt1t - A_1_vec[0:M,1:-1])**2).mean()\n",
    "insample_msfe_ar = tvp_ar.insample_msfe()\n",
    "\n",
    "print(f'MSD: {MSD} | insample MSFE: {insample_msfe_ar}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp_ar.sigma_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_h = 8\n",
    "\n",
    "msfe_ar, aapl_ar = tvp_ar.calculate_metrics(total_h, constant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_msfe = np.zeros(total_h)\n",
    "for h in range(total_h):\n",
    "    ratio_msfe[h] = msfe_ar[h]/np.mean((y_own[:,(train-1+h):] - y_own[:,(train-2):-(h+1)])**2,1)[0]\n",
    "    print(f'Ratio AR_VI/RW ({h+1}-step ahead): {np.round(ratio_msfe[h],4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mt1t.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1_vec[:M,:].mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVP-VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default implementation from statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "var_ols = VAR(y.T)\n",
    "results_var = var_ols.fit(1, trend='nc')\n",
    "results_var.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (400,) (400,149) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-7cbfc4d1be1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA_1_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (400,) (400,149) "
     ]
    }
   ],
   "source": [
    "np.squeeze(results_var.coefs).reshape(M*M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_const = np.mean((np.repeat(np.squeeze(results_var.coefs).reshape(M*M),149).reshape(M*M,149) - A_1_vec[:,1:train])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_tvp = np.mean((full_mt1t - A_1_vec[:,1:train])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.817871705297146"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd_tvp/msd_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp_var = TVPVARModel(X_own, y_own.T, p, train, False, homoskedastic=True)\n",
    "tvp_var.iterations = 50\n",
    "tvp_var.initialize_priors(prior='lasso')#, prior_parameters = {'a0':10, 'b0':10})\n",
    "mt1t, __ = tvp_var.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp_var.bt_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSD = ((mt1t - A_1_vec[:,1:train])**2).mean()\n",
    "insample_msfe_var = tvp_var.insample_msfe()\n",
    "\n",
    "print(f'MSD: {MSD} | insample MSFE: {insample_msfe_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the first coefficient *(estimated versus true)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mt1t[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A_1_vec[0,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tvp_var.sigma_t[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_h = 8\n",
    "\n",
    "msfe_var, aapl_var = tvp_var.calculate_metrics(total_h, constant=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_msfe = np.zeros((total_h,M))\n",
    "for h in range(total_h):\n",
    "    ratio_msfe[h,:] = msfe_var[h]/np.mean((y_own[:,(train-1+h):] - y_own[:,(train-2):-(h+1)])**2,1)[0]\n",
    "    print(f'Ratio VAR_VI/RW ({h+1}-step ahead): {np.round(ratio_msfe[h].mean(),4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msfe_var.mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tvp_var.y_pred[:,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_own[0,train:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
